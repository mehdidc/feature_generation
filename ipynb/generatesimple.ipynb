{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcherti/work/code/external/scikit-learn/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,compiledir_format=\"ipynb_cpu\"'\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import lasagne\n",
    "\n",
    "from tasks import check\n",
    "from lasagne import layers as L\n",
    "\n",
    "from lasagnekit.misc.plot_weights import dispims_color, tile_raster_images\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imsave\n",
    "\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from lasagnekit.misc.plot_weights import tile_raster_images\n",
    "import numpy as np\n",
    "from lasagnekit.misc.plot_weights import dispims_color\n",
    "from skimage.io import imsave\n",
    "from helpers import salt_and_pepper\n",
    "import lasagne\n",
    "import pickle\n",
    "from lasagne import layers\n",
    "\n",
    "def load_gan_model(filename):\n",
    "    import dcgan\n",
    "    \n",
    "    data = pickle.load(open(filename))\n",
    "    gen = data['generator']\n",
    "    discr = data['discriminator']\n",
    "    return gen, discr\n",
    "\n",
    "def sample(x):\n",
    "    return (np.random.uniform(size=x.shape) <= x).astype(np.float32)\n",
    "\n",
    "def floatX(x):\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, max(len(inputs) - batchsize + 1, len(inputs)), batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "from tools.brushstroke.common import to_grid_of_images, disp_grid\n",
    "from tools.brushstroke.common import load_model, get_bias, get_scale\n",
    "from lasagnekit.misc.draw_net import draw_to_file\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lightjob.cli import load_db\n",
    "db = load_db()\n",
    "s = db.get_job_by_summary('8b4064243348c6285cfdad39c84fee88')['content']['model_summary']\n",
    "filename = \"../jobs/results/{}/model.pkl\".format(s)\n",
    "\n",
    "filename ='../training/vertebrate/verte16/model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capsule, data, layers = load_model(filename)\n",
    "c, w, h = layers['input'].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw_to_file(L.get_all_layers(layers['output']), 'out.svg')\n",
    "SVG('out.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.load()\n",
    "X = data.X[0:100]\n",
    "X = capsule.preprocess(X)\n",
    "Xrec = capsule.reconstruct(X)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(disp_grid(Xrec, border=1, bordercolor=(0.3,0.3,0.3)), interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProgramNeural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_t = T.tensor4()\n",
    "get_coords = theano.function([X_t], L.get_output(layers['coord_0_normalized'], X_t))\n",
    "get_repr = theano.function([X_t], L.get_output(layers['repr_0_normalized'], X_t))\n",
    "\n",
    "C = T.tensor3()\n",
    "R = T.tensor3()\n",
    "render = theano.function(\n",
    "    [C, R],\n",
    "    L.get_output(layers['output'], \n",
    "                 {layers['coord_0_normalized']: C, layers['repr_0_normalized']: R}, \n",
    "                 deterministic=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_layers = [l for l in layers.keys() if 'normalized' in l]\n",
    "get_feats = theano.function([X_t], [L.get_output(layers[l], X_t) for l in feat_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_coords_1 = theano.function([X_t], L.get_output(layers['coord_1_0_normalized'], X_t))\n",
    "#get_rel_coords_1 = theano.function([X_t], L.get_output(layers['coord_5_0'], X_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.X[0:9]\n",
    "X = capsule.preprocess(X)\n",
    "coords = get_coords(X)\n",
    "reprs = get_repr(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reprs_ = reprs.copy()\n",
    "coords_ = coords.copy()\n",
    "coords_[:]=0.5\n",
    "reprs_[:]=0\n",
    "#coords_[:]=-10\n",
    "#coords_[:,0]=0.5\n",
    "#reprs_[:,0,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xrec = render(coords_, reprs_)\n",
    "Xrec = Xrec\n",
    "img = disp_grid(Xrec, border=1, bordercolor=(0.3,0,0))\n",
    "imsave('out.png', img)\n",
    "Image('out.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only come here To check vertebrate  convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(layers)\n",
    "code_layers = ['sparse0', 'sparse1', 'sparse2', 'sparse3']\n",
    "X_t = T.tensor4()\n",
    "encode = theano.function(\n",
    "    [X_t], \n",
    "    [L.get_output(layers[cc], X_t) for cc in code_layers]\n",
    ")\n",
    "code_t = [T.tensor4() for _ in code_layers]\n",
    "decode = theano.function(\n",
    "    code_t,\n",
    "    L.get_output(layers['output'], {layers[name]: t for name, t in zip(code_layers, code_t)})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.X[0:100]\n",
    "X=capsule.preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = encode(X)\n",
    "Xrec = decode(*C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = C[3][0][:, None, :, :]\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(disp_grid(m, border=1, bordercolor=(0.3, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = list(encode(X))\n",
    "cc = []#include these\n",
    "for i in set(range(len(C))) - set(cc):\n",
    "    C[i][:] = 0\n",
    "C_zeros = [np.zeros_like(c) for c in C]\n",
    "M = [3]#change these\n",
    "\n",
    "for _ in range(1):\n",
    "    for i in M:\n",
    "        F = C[i].shape[1]\n",
    "        W = C[i].shape[2]\n",
    "        H = C[i].shape[3]\n",
    "        N = min(C[i].shape[0], F)\n",
    "        C[i][np.arange(N), \n",
    "             np.arange(N), \n",
    "             np.random.randint(0, W, size=N), \n",
    "             np.random.randint(0, H, size=N)\n",
    "             #0,\n",
    "             #0,\n",
    "        ] = 20\n",
    "\n",
    "\"\"\"\n",
    "for i in M:\n",
    "    for n in range(N):\n",
    "        F = C[i].shape[1]\n",
    "        W = C[i].shape[2]\n",
    "        H = C[i].shape[3]\n",
    "        C[i][n, np.arange(F), np.random.randint(0, H, size=F), np.random.randint(0, W, size=F)] = 10\n",
    "\"\"\"\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "Xrec = decode(*C)\n",
    "X_rec_zero = decode(*C_zeros)\n",
    "\n",
    "res = Xrec# - X_rec_zero\n",
    "recons = dispims_color(res.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3)), border=1, bordercolor=(0.5,0.5,0.5))\n",
    "plt.imshow(recons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(C)):\n",
    "    print(C[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viz features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbpixels = 28*28\n",
    "for name, layer in layers.items():\n",
    "    if hasattr(layer, \"W\"):\n",
    "        W = layer.W.get_value()\n",
    "        if len(W.shape)==2 and (W.shape[0] == nbpixels or W.shape[1] == nbpixels):\n",
    "            nbpixels = c*w*h\n",
    "            if W.shape[0] == nbpixels:\n",
    "                W = W.T\n",
    "            W = W.reshape((W.shape[0], c, w, h))\n",
    "            W = W.transpose((0, 2, 3, 1))\n",
    "            W = W * np.ones((1, 1, 1, 3))\n",
    "        elif len(W.shape) == 4 and W.shape[1] in (1, 3):\n",
    "            W = W.transpose((0, 2, 3, 1))\n",
    "            W = W * np.ones((1, 1, 1, 3))\n",
    "        elif len(W.shape) == 4 and W.shape[0] in (1, 3):\n",
    "            W = W.transpose((1, 2, 3, 0))\n",
    "            W = W * np.ones((1, 1, 1, 3))\n",
    "        else:\n",
    "            print(W.shape)\n",
    "            continue\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        plt.axis('off')\n",
    "        img = dispims_color(W, border=1)\n",
    "        plt.imshow(img, interpolation='none')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterative refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "c=1\n",
    "if c == 3:\n",
    "    external_data = load_data(dataset='lfw', w=w, h=h)\n",
    "    external_data = external_data.X\n",
    "    external_data = external_data.reshape((external_data.shape[0], c, w, h))\n",
    "    \n",
    "if c == 1:\n",
    "    from lasagnekit.datasets.rescaled import Rescaled\n",
    "    external_data = load_data(dataset='digits', w=w, h=h)\n",
    "    external_data = Rescaled(external_data, (w, h))\n",
    "    external_data.load()\n",
    "    external_data = external_data.X[0:100]\n",
    "    external_data = external_data.reshape((external_data.shape[0], c, w, h))\n",
    "    external_data = external_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "c=1\n",
    "N = 100 # nb of examples to generate\n",
    "nb_iter = 100# nb iterations for generation\n",
    "\n",
    "do_sample = False\n",
    "do_binarize = True\n",
    "do_noise = False\n",
    "noise_pr = 0.1\n",
    "do_gaussian_noise = False\n",
    "gaussian_noise_std = 0.001\n",
    "thresh = 'moving'\n",
    "\n",
    "init_by_external = False\n",
    "whitepx_ratio = 0.25\n",
    "if init_by_external:\n",
    "    s = floatX(external_data[0:N])\n",
    "else:\n",
    "    s = floatX(np.random.uniform(0, 1, size=(N, c, w, h)))\n",
    "\n",
    "samples = []\n",
    "samples.append(s.copy()[np.newaxis, :, :, :, :])\n",
    "\n",
    "nz = np.random.normal(0, gaussian_noise_std, size=s.shape).astype(np.float32)\n",
    "loss = []\n",
    "nz = np.random.normal(0, gaussian_noise_std, size=s.shape).astype(np.float32)\n",
    "for i in tqdm(range(nb_iter)):\n",
    "    sprev = s      \n",
    "    if do_noise:\n",
    "        s = (np.random.uniform(size=s.shape) <= (1 - noise_pr)) * s\n",
    "        s = s.astype(np.float32)\n",
    "    if do_gaussian_noise:\n",
    "        nz = np.random.normal(0, gaussian_noise_std, size=s.shape).astype(np.float32)\n",
    "        s += nz\n",
    "    s = (capsule.reconstruct(s))\n",
    "\n",
    "    if do_sample:\n",
    "        s = np.random.binomial(n=1, p=s, size=s.shape).astype('float32')# binarize by sampling\n",
    "    if do_binarize:\n",
    "        if thresh == 'moving':\n",
    "            vals = s.flatten()\n",
    "            vals = vals[np.argsort(vals)]\n",
    "            thresh_ = vals[-int(whitepx_ratio * len(vals)) - 1]\n",
    "        else:\n",
    "            thresh_ = thresh\n",
    "        s = s > thresh_\n",
    "    s = s.astype(np.float32)\n",
    "    samples.append(s.copy()[np.newaxis, :, :, :, :])\n",
    "\n",
    "    score = np.abs(s - sprev).sum()\n",
    "    if score == 0:\n",
    "        print('end')\n",
    "        break\n",
    "    #print(score)\n",
    "    loss.append(score)\n",
    "print(score)\n",
    "samples = np.concatenate(samples, axis=0) # all samples from all timesteps in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show images generated at last iteration\n",
    "for s in (samples[-1],):\n",
    "    s = s * np.ones((1, 3, 1, 1))\n",
    "    s = s.transpose((0, 2, 3, 1))\n",
    "    img = dispims_color(s, border=2, bordercolor=(0.3, 0, 0), )\n",
    "    imsave('out.png', img)\n",
    "Image('out.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample samples and iterations\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "sw, sh = samples.shape[0:2]\n",
    "samples_ = samples.copy()\n",
    "samples_ = samples_.reshape((sw*sh, c, w, h))\n",
    "samples_ = samples_.transpose((0, 2, 3, 1))\n",
    "samples_ = samples_ * np.ones((1, 1, 1, 3))\n",
    "img = dispims_color(samples_, shape=(sw, sh), border=1, bordercolor=(0.3,0,0))\n",
    "imsave('out.png', img)\n",
    "Image('out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts.imgtovideo import imgs_to_video\n",
    "from tools.brushstroke.common import embed_video\n",
    "imgs = []\n",
    "for s in samples:\n",
    "    img = dispims_color(s.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3)), border=2, bordercolor=(0.3, 0, 0))\n",
    "    imgs.append(img)\n",
    "if os.path.exists('out.mp4'):\n",
    "    os.remove('out.mp4')\n",
    "imgs_to_video(imgs, out='out.mp4', verbose=10, framerate=10, rate=10)\n",
    "embed_video('out.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video of the last row for brush stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4()\n",
    "encode = theano.function(\n",
    "    [X], \n",
    "    L.get_output(layers['brush'], X)\n",
    ")\n",
    "\n",
    "encode_coords = theano.function(\n",
    "    [X],\n",
    "    L.get_output(layers['coord'], X)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias = layers['bias'].b.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = capsule.preprocess(samples[-2][0:16*16])\n",
    "xx = X.copy()\n",
    "xx = xx.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3))\n",
    "source = dispims_color(xx, border=0)\n",
    "\n",
    "    \n",
    "y = encode(X)\n",
    "\n",
    "imgs = []\n",
    "for t in range(y.shape[1]):\n",
    "    yy = y[:, t]\n",
    "    yy = yy[:, :, :, None] * np.ones((1, 1, 1, 3))\n",
    "    yy = sigmoid(yy+bias) > 0.5\n",
    "    yy = yy.astype(np.float32)\n",
    "    img = dispims_color(yy, border=0) \n",
    "    plt.imshow(img)\n",
    "    imgs.append(img)\n",
    "\n",
    "seq_imgs = imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = [np.zeros_like(imgs[0])] + imgs\n",
    "img_aggreg = np.zeros((img.shape[0], img.shape[1]*2, 3))\n",
    "img_aggreg[0:source.shape[0], 0:source.shape[1]] = source\n",
    "img_aggreg[:, source.shape[1]:source.shape[1]+img.shape[1]] = img\n",
    "imsave('out.png', img_aggreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists('out.mp4'):\n",
    "    os.remove('out.mp4')\n",
    "imgs_to_video(imgs, out='out.mp4', verbose=1, framerate=8, rate=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## project into feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hid = []\n",
    "d = []\n",
    "for i in range(10):\n",
    "    X = data.X\n",
    "    data.load()\n",
    "    d.append(capsule.preprocess(X).transpose((0, 2 ,3 , 1))  * np.ones((1, 1, 1, 3)))\n",
    "    C = encode(capsule.preprocess(X))\n",
    "    if type(C) == list:\n",
    "        C = [c.reshape(c.shape[0], -1) for c in C]\n",
    "        #C = C[-1]\n",
    "        C = np.concatenate(C, axis=1)        \n",
    "    hid.append(C)\n",
    "d = np.concatenate(d, axis=0)\n",
    "hid = np.concatenate(hid, axis=0)\n",
    "hid = hid.reshape((hid.shape[0], -1))\n",
    "print(hid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mf = PCA(n_components=2)\n",
    "mf = TSNE(n_components=2)\n",
    "h2d = mf.fit_transform(hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mf = PCA(n_components=2)\n",
    "mf = TSNE(n_components=2)\n",
    "d2d = mf.fit_transform(d.reshape(d.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tools.viz.image_scatter import image_scatter\n",
    "img = image_scatter(h2d, d, 20)\n",
    "imsave('out_scatter.png', img)\n",
    "Image('out_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = image_scatter(d2d, d, 20)\n",
    "imsave('out_scatter_data.png', img)\n",
    "Image('out_scatter_data.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_transf_orig = external_data[0:100].copy()\n",
    "\n",
    "\n",
    "im = X_transf_orig.copy().astype(np.float32)\n",
    "imgs = []\n",
    "for i in tqdm(range(100)):\n",
    "    im = im + (capsule.reconstruct(im) - im)\n",
    "    imgs.append(im.copy())\n",
    "    \n",
    "from scripts import imgtovideo\n",
    "x = []\n",
    "for img in imgs:\n",
    "    img = img * np.ones((1, 3, 1, 1))\n",
    "    img = img.transpose((0, 2, 3, 1))\n",
    "    x.append(dispims_color(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm out.mp4\n",
    "imgs_to_video(x, out='out.mp4', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_video('out.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forced generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen, discr = load_gan_model('/home/mcherti/work/code/lasagne-dcgan/fonts.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4()\n",
    "Xinit = X\n",
    "nb_steps = 4\n",
    "for i in range(nb_steps):\n",
    "    X = L.get_output(layers['output'], X)\n",
    "score = L.get_output(discr, X)\n",
    "loss = (score).mean()\n",
    "grad = theano.grad(loss, Xinit)\n",
    "get_grad = theano.function([Xinit], grad)\n",
    "get_loss = theano.function([Xinit], loss)\n",
    "get_gen = theano.function([Xinit], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "def eval_loss(x0):\n",
    "    x0 = x0.reshape((nb, c, w, h))\n",
    "    return -get_loss(x0.astype(np.float32)).astype('float64')\n",
    "\n",
    "def eval_grad(x0):\n",
    "    x0 = x0.reshape((nb, c, w, h))\n",
    "    return get_grad(x0.astype(np.float32)).flatten().astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = 100\n",
    "x = np.random.uniform(size=(nb, c, w, h))\n",
    "x = x.astype(np.float32)\n",
    "for i in range(40):\n",
    "    #x, _, _ = scipy.optimize.fmin_l_bfgs_b(eval_loss, x.flatten(), fprime=eval_grad, maxfun=1)\n",
    "    #x = x.reshape((nb, c, w, h)).astype(np.float32)\n",
    "    x += 0.1 * get_grad(x)\n",
    "    print(get_loss(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = get_gen(x) * np.ones((1, 3, 1, 1))\n",
    "img = img.transpose((0, 2, 3, 1))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "img = dispims_color(img, border=1, bordercolor=(10, 10, 10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datakit.mnist import MNIST\n",
    "data = MNIST('train')\n",
    "data.load()\n",
    "X_train = data.X.reshape((data.X.shape[0], 1, 28, 28))\n",
    "y_train = data.y\n",
    "def transform(X):\n",
    "    h = []\n",
    "    for i in range(0, X.shape[0], 128):\n",
    "        C = encode(X[i:i + 128])\n",
    "        hh = np.concatenate([cc.max(axis=(2, 3)).reshape((cc.shape[0], -1)) for cc in C], axis=1)      \n",
    "        h.append(hh)\n",
    "    h = np.concatenate(h, axis=0)\n",
    "    return h\n",
    "\n",
    "X_train = transform(X_train)\n",
    "\n",
    "data = MNIST('test')\n",
    "data.load()\n",
    "X_test = data.X.reshape((data.X.shape[0], 1, 28, 28))\n",
    "X_test = transform(X_test)\n",
    "y_test = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xrec = capsule.reconstruct(data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = T.matrix()\n",
    "X = T.tensor4()\n",
    "sample = theano.function([Z], L.get_output(layers['output'], {layers['z_sample']: Z}))\n",
    "\n",
    "pred_z = theano.function([X], L.get_output(layers['z_mu'], X))\n",
    "\n",
    "z_size = layers['z_sample'].output_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = data.X[0:5000]\n",
    "z = pred_z(capsule.preprocess(x))\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "cmap = plt.get_cmap('jet', 10)\n",
    "cmap.set_under('gray')\n",
    "r_inp = np.random.uniform(size=(100, w*h*c)).astype(np.float32)\n",
    "r = pred_z(capsule.preprocess(r_inp))\n",
    "plt.scatter(z[:, 0], z[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = 121\n",
    "if z_size == 2:\n",
    "    x = np.linspace(-1, 1, np.sqrt(nb))\n",
    "    y = np.linspace(-1, 1, np.sqrt(nb))\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z_samples = np.vstack((x, y)).T\n",
    "else:\n",
    "    #z_samples = np.random.normal(0, 1, size=(nb, z_size))\n",
    "    #z_samples[:, :]=0\n",
    "    z_samples[:, 10]=np.linspace(-8, 8, len(z_samples))\n",
    "z_samples = z_samples.astype(np.float32)\n",
    "x_samples = sample(z_samples)\n",
    "\n",
    "x_samples = x_samples.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "img = dispims_color(x_samples)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imsave('out.png', img)\n",
    "Image('out.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen, discr = load_gan_model('../tools/mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = T.tensor4()\n",
    "discr_fn = theano.function([X], L.get_output(discr, X))\n",
    "\n",
    "Z = T.matrix()\n",
    "gen_fn = theano.function([Z], L.get_output(gen, Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_grad_fn = theano.function([X, Z], theano.grad( ((L.get_output(gen, Z)-X)**2).mean()  , Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_grad_n = theano.function([X], theano.grad(L.get_output(discr, X).mean(), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_set(x, w, h, **kw):\n",
    "    x_out = np.empty((x.shape[0], 1, w, h))\n",
    "    for i in range(len(x)):\n",
    "        x_out[i, 0] = resize(x[i, 0], (w, h), **kw)\n",
    "    return x_out.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(gen.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.uniform(size=(9, 1, 28, 28)).astype(np.float32)\n",
    "Z_of_X = np.random.uniform(-1, 1, size=(x.shape[0], 100)).astype(np.float32)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    #x += np.random.normal(0, 0.5, size=x.shape)\n",
    "    x = capsule.reconstruct(x)\n",
    "    x = x.astype(np.float32)\n",
    "    x = resize_set(x, 32, 32)\n",
    "    if True:\n",
    "        z_rec = np.random.uniform(-1, 1, size=(x.shape[0], 100)).astype(np.float32)\n",
    "        for _ in range(10):\n",
    "            g = z_grad_fn(x, z_rec)\n",
    "            z_rec -= 0.001*g\n",
    "        \n",
    "        gen = gen_fn(z_rec)\n",
    "        gen =- gen.min(axis=0, keepdims=True)\n",
    "        gen /= gen.max(axis=0, keepdims=True)\n",
    "        x = x + (x - gen)\n",
    "    if False:\n",
    "        for _ in range(30):\n",
    "            g = x_grad_n(x)\n",
    "            x += 0.001*g\n",
    "    x -= x.min(axis=(1, 2, 3), keepdims=True)\n",
    "    x /= x.max(axis=(1, 2, 3), keepdims=True) \n",
    "\n",
    "    #x -= x.min(axis=0, keepdims=True)\n",
    "    #x /= x.max(axis=0, keepdims=True) \n",
    "\n",
    "    x = resize_set(x, 28, 28, preserve_range=True)\n",
    "    \n",
    "    #x = x > 0.3\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "#x = resize_set(x, 32, 32)\n",
    "print((discr_fn(x)).flatten().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img =  dispims_color(x.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3)))\n",
    "imsave('out.png', img)\n",
    "Image('out.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagnekit.datasets.mnist import MNIST\n",
    "data_train = MNIST(which='train')\n",
    "data_train.load()\n",
    "data_test = MNIST(which='test')\n",
    "data_test.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_feats(f):\n",
    "    f = map(lambda f_i:f_i.reshape((f_i.shape[0], -1)), f)\n",
    "    f = np.concatenate(f, axis=1)\n",
    "    return f\n",
    "train_feats = list(get_feats(capsule.preprocess(data_train.X)))\n",
    "train_feats.append(data_train.X)\n",
    "train_feats = preprocess_feats(train_feats)\n",
    "test_feats = list(get_feats(capsule.preprocess(data_test.X)))\n",
    "test_feats.append(data_test.X)\n",
    "test_feats = preprocess_feats(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(PCA(n_components=1000), LogisticRegression())\n",
    "#clf = LogisticRegression()\n",
    "clf.fit(train_feats, data_train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(clf.predict(train_feats)==data_train.y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(clf.predict(test_feats) == data_test.y).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
