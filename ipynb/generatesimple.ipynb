{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=gpu\"\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from tasks import check\n",
    "from scripts import manifold\n",
    "from lasagne import layers as L\n",
    "\n",
    "from lasagnekit.misc.plot_weights import dispims_color, tile_raster_images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imsave\n",
    "\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from image_scatter import image_scatter\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from lasagnekit.misc.plot_weights import tile_raster_images\n",
    "import numpy as np\n",
    "\n",
    "from helpers import salt_and_pepper\n",
    "def sample(x):\n",
    "    return (np.random.uniform(size=x.shape) <= x).astype(np.float32)\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, max(len(inputs) - batchsize + 1, len(inputs)), batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = check(\n",
    "    what=\"notebook\", \n",
    "    filename=\"../training/fonts/dense2/model.pkl\",\n",
    "    force_w=28,\n",
    "    force_h=28,\n",
    "    dataset=\"fonts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capsule, data, layers, w, h, c = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.tensor4()\n",
    "encode = theano.function([X], L.get_output(layers['hid2'], X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viz features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, layer in layers.items():\n",
    "    if hasattr(layer, \"W\"):\n",
    "        W = layer.W.get_value()\n",
    "        if len(W.shape)==2:\n",
    "            nbpixels = c*w*h\n",
    "            if W.shape[0] == nbpixels:\n",
    "                W = W.T\n",
    "            a, b = w, h\n",
    "        else:\n",
    "            W = W.reshape((W.shape[0]*W.shape[1], W.shape[2], W.shape[3]))\n",
    "            a, b = W.shape[1:]\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        s = int(np.sqrt(W.shape[0]))\n",
    "        plt.axis('off')\n",
    "        img=tile_raster_images(W, (a, b), (s, s))\n",
    "        plt.imshow(img, cmap=\"gray\", interpolation='none')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterative refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "N = 100\n",
    "s = np.random.uniform(0, 1, size=(N, c, w, h))\n",
    "s = s.astype(np.float32)\n",
    "samples = []\n",
    "samples.append(s.copy()[None, :, :, :, :])\n",
    "nb_iter = 60\n",
    "loss = []\n",
    "for i in tqdm(range(nb_iter)):\n",
    "    sprev = s  \n",
    "    #s = s > 0.6\n",
    "    s = capsule.reconstruct(s)\n",
    "    s = s.astype(np.float32)\n",
    "    samples.append(s.copy()[None, :, :, :, :])\n",
    "    s = np.random.binomial(n=1, p=s, size=s.shape).astype('float32')# binarize by sampling\n",
    "    #s = s > 0.6\n",
    "    score = np.abs(s - sprev).sum()\n",
    "    loss.append(score)\n",
    "samples = np.concatenate(samples, axis=0)\n",
    "print(samples.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "h = 28\n",
    "sw, sh = samples.shape[0:2]\n",
    "samples_ = samples.copy()\n",
    "samples_ = samples_.reshape((sw*sh, c, w, h))\n",
    "samples_ = samples_.transpose((0, 2, 3, 1))\n",
    "samples_ = samples_ * np.ones((1, 1, 1, 3))\n",
    "img = dispims_color(samples_)\n",
    "imsave('out.png', img)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = []\n",
    "d = []\n",
    "for i in range(10):\n",
    "    d.append(capsule.preprocess(data.X).transpose((0, 2 ,3 , 1))  * np.ones((1, 1, 1, 3)))\n",
    "    h.append(encode(capsule.preprocess(data.X)))\n",
    "\n",
    "d = np.concatenate(d, axis=0)\n",
    "h = np.concatenate(h, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mf = IncrementalPCA(n_components=2, batch_size=1024)\n",
    "mf = PCA(n_components=2)\n",
    "#mf = TSNE(n_components=2, verbose=1)\n",
    "h2d = mf.fit_transform(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf = PCA(n_components=2)\n",
    "#mf = IncrementalPCA(n_components=2, batch_size=1024)\n",
    "#mf = TSNE(n_components=2, verbose=1)\n",
    "d2d = mf.fit_transform(d.reshape(d.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = image_scatter(h2d, d, 80)\n",
    "imsave('out_scatter.png', img)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = image_scatter(d2d, d, 80)\n",
    "imsave('out_scatter_data.png', img)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transferability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagnekit.datasets.mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "mnist.load()\n",
    "X_transf_orig = mnist.X.reshape((mnist.X.shape[0], c, w, h))\n",
    "X_transf_orig = X_transf_orig[mnist.y==5]\n",
    "X_transf_orig = X_transf_orig[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_transf_rec = X_transf_orig.copy().astype(np.float32)\n",
    "X_transf_rec = X_transf_rec\n",
    "for i in range(1):\n",
    "    X_transf_rec = capsule.reconstruct(X_transf_rec)\n",
    "    print(((X_transf_rec - capsule.reconstruct(X_transf_rec))**2).sum(axis=(1, 2, 3)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_transf = X_transf_orig.transpose((0, 2, 3, 1))\n",
    "X_transf = X_transf * np.ones((1, 1, 1, 3))\n",
    "\n",
    "X_transf_rec = X_transf_rec.transpose((0, 2, 3, 1))\n",
    "X_transf_rec = X_transf_rec * np.ones((1, 1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "img = dispims_color(X_transf_rec[0:500])\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "img = dispims_color(X_transf[0:500])\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## moment matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import rectify, sigmoid\n",
    "from lasagne import updates\n",
    "z_dim = 10\n",
    "Z = T.matrix()\n",
    "h=28\n",
    "z_in = L.InputLayer((None, z_dim))\n",
    "h1 = L.DenseLayer(z_in, num_units=100, nonlinearity=rectify)\n",
    "h2 = L.DenseLayer(h1, num_units=500, nonlinearity=rectify)\n",
    "x = L.DenseLayer(h2, num_units=c*w*h, nonlinearity=sigmoid)\n",
    "x = L.ReshapeLayer(x, ([0], c, w, h))\n",
    "gen = theano.function([Z], L.get_output(x, Z))\n",
    "\n",
    "\n",
    "def transform_r(s):\n",
    "    return s.mean(axis=0)\n",
    "    rr = s[:, None, :]\n",
    "    rrr = s[:, :, None]\n",
    "    return (rr*rr).mean(axis=0)\n",
    "\n",
    "rx = L.get_output(layers['hid2'], L.get_output(x, Z))\n",
    "rX = L.get_output(layers['hid2'], X)\n",
    "\n",
    "\n",
    "loss = ((rx - rX) ** 2).mean()\n",
    "#loss = ((transform_r(rx) - transform_r(rX))**2).sum()\n",
    "#loss = ((rx.mean(axis=0) - rX.mean(axis=0))**2).sum()\n",
    "#loss = (((rx**2).mean(axis=0) - (rX**2).mean(axis=0))**2).sum()\n",
    "\n",
    "\n",
    "\n",
    "#loss = ((rx - rX)**2).mean()\n",
    "\n",
    "params = L.get_all_params(x, trainable=True)\n",
    "grad_updates = updates.adam(loss, params, learning_rate=0.01)\n",
    "train_fn = theano.function([Z, X], loss, updates=grad_updates)\n",
    "loss_fn = theano.function([Z, X], loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagnekit.datasets.helpers import split\n",
    "from time import time\n",
    "print('Loading data...')\n",
    "\n",
    "def preprocess(data):\n",
    "    return data.reshape((data.shape[0], c, w, h))\n",
    "\n",
    "train_full = MNIST(which='train')\n",
    "train_full.load()\n",
    "train_full.X = preprocess(train_full.X)\n",
    "#train_full.X = train_full.X[0:128*2]\n",
    "\n",
    "train, valid = split(train_full, test_size=0.16667) # 10000 examples in validation set\n",
    "\n",
    "test = MNIST(which='test')\n",
    "test.load()\n",
    "test.X = preprocess(test.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from tabulate import tabulate\n",
    "from\n",
    "nb_epochs = 100\n",
    "batchsize = 128\n",
    "#learning_rate.set_value(np.array(lr).astype(np.float32))\n",
    "history = []\n",
    "print('Training...')\n",
    "\n",
    "\n",
    "z_full = \n",
    "z_full = np.random.uniform(-1, 1, size=(train_X_full.shape[0], z_dim)).astype(np.float32)\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    train_time = []\n",
    "    train_X_full = train.X\n",
    "\n",
    "    train_y_full = train.y\n",
    "    for train_X, z in iterate_minibatches(train_X_full, z_full, batchsize):\n",
    "        # Train one mini=batch\n",
    "        t = time()\n",
    "        train_fn(z, train_X)\n",
    "        train_time.append(time() - t)\n",
    "    \n",
    "    stats = OrderedDict()\n",
    "    z = np.random.uniform(-1, 1, size=(train.X.shape[0], z_dim)).astype(np.float32)\n",
    "    stats['train_loss'] = loss_fn(z, train.X)\n",
    "    z = np.random.uniform(-1, 1, size=(valid.X.shape[0], z_dim)).astype(np.float32)\n",
    "    stats['valid_losss'] = loss_fn(z, valid.X)\n",
    "    stats['train_time'] = np.sum(train_time)\n",
    "    stats['epoch'] = epoch\n",
    "    \n",
    "    history.append(stats)\n",
    "    print(tabulate([stats], headers=\"keys\"))\n",
    "    #lr = lr * lr_decay\n",
    "    #learning_rate.set_value(np.array(lr).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.random.uniform(-1, 1, size=(256, z_dim)).astype(np.float32)\n",
    "xgen = gen(z)\n",
    "xgen = xgen.reshape((xgen.shape[0], c, w, h))\n",
    "xgen = xgen.transpose((0, 2, 3, 1))\n",
    "xgen = xgen * np.ones((1, 1, 1, 3))\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "img = dispims_color(xgen, border=1)\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
