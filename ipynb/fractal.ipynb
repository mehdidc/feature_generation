{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,compiledir_format=\"ipynb_compiledir_%(platform)s-%(processor)s-%(python_version)s-%(python_bitwidth)s\"'\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "\n",
    "from tasks import check as load_filename\n",
    "from scripts.imgtovideo import imgs_to_video\n",
    "from data import load_data\n",
    "from helpers import salt_and_pepper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lasagne import layers as L\n",
    "\n",
    "from lasagnekit.misc.plot_weights import dispims_color, tile_raster_images\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "\n",
    "def load_model(filename, **kw):\n",
    "\n",
    "    model = load_filename(\n",
    "        what=\"notebook\", \n",
    "        filename=filename, \n",
    "        **kw\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_brush_func(layers):\n",
    "    if 'biased_output' in layers:\n",
    "        bias = layers['biased_output'].b.get_value()\n",
    "    elif 'bias' in layers:\n",
    "        bias = layers['bias'].b.get_value()\n",
    "    else:\n",
    "        bias = np.array(0.1)\n",
    "\n",
    "    bias = bias[np.newaxis, np.newaxis, :, np.newaxis, np.newaxis]\n",
    "\n",
    "    if 'scaled_output' in layers:\n",
    "        scale = layers['scaled_output'].scales.get_value()\n",
    "    elif 'scale' in layers:\n",
    "        scale = layers['scale'].scales.get_value()\n",
    "    else:\n",
    "        scale = np.array((1.,))\n",
    "    scale = scale[np.newaxis, np.newaxis, :, np.newaxis, np.newaxis]\n",
    "\n",
    "    \n",
    "    X = T.tensor4()\n",
    "\n",
    "    B = L.get_output(layers['brush'], X)\n",
    "    if len(layers['brush'].output_shape) == 4: # (ex, t, w, h)\n",
    "        B = B.dimshuffle(0, 1, 'x', 2, 3)\n",
    "    \n",
    "    fn = theano.function(\n",
    "        [X], \n",
    "        T.nnet.sigmoid(B * scale + bias)\n",
    "    )\n",
    "    return fn\n",
    "\n",
    "def build_encode_func(layers):\n",
    "    w = layers['output'].output_shape[2]\n",
    "    X = T.tensor4()\n",
    "    fn = theano.function(\n",
    "        [X], \n",
    "        T.nnet.sigmoid(L.get_output(layers['coord'], X)[:, :, 0:2]) * w\n",
    "    )\n",
    "    return fn\n",
    "\n",
    "def to_grid_of_images(seq_imgs, **kw):\n",
    "    y = seq_imgs\n",
    "    imgs = []\n",
    "    for t in range(y.shape[1]):\n",
    "        yy = y[:, t]\n",
    "        if yy.shape[1] == 1:\n",
    "            yy = yy[:, 0, :, :, np.newaxis] * np.ones((1, 1, 1, 3))\n",
    "        else:\n",
    "            yy = yy.transpose((0, 2, 3, 1))\n",
    "        img = dispims_color(yy, **kw)\n",
    "        imgs.append(img)\n",
    "    return imgs\n",
    "\n",
    "def seq_to_video(seq, filename='out.mp4', verbose=1, framerate=8, rate=8, **kw):\n",
    "    # shape of seq should be : (examples, time, c, w, h)\n",
    "    seq = to_grid_of_images(seq, **kw)\n",
    "    seq = [np.zeros_like(seq[0])] + seq\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    imgs_to_video(seq, out=filename, verbose=verbose, framerate=framerate, rate=rate)\n",
    "\n",
    "def embed_video(filename):\n",
    "    video = open(filename, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                </video>'''.format(encoded.decode('ascii')))\n",
    "def disp_grid(imgs, **kw):\n",
    "    # shape of imgs should be : (examples, color, w, h)\n",
    "    out = dispims_color(imgs.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3)), **kw)\n",
    "    return out\n",
    "def normalize(img):\n",
    "    img = img.copy()\n",
    "    img -= img.min()\n",
    "    img /= img.max()\n",
    "    return img\n",
    "\n",
    "from lasagnekit.datasets.mnist import MNIST\n",
    "from skimage.util import pad\n",
    "from IPython import display\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 16, 16)\n",
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 100000, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 800, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_a1, data, layers, w, h, c = load_model(\"../training/fractal/a/model.pkl\", \n",
    "                                            dataset=\"rescaled_digits\", \n",
    "                                            force_w=16, force_h=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 128, (128000, 64))\n",
      "loaded\n",
      "(128, 128, (128000, 64))\n",
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 8, 8)\n",
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 100000, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 800, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_b1, data, layers, w, h, c = load_model(\"../training/fractal/b/model.pkl\", \n",
    "                                            dataset=\"random_cropped_digits\", \n",
    "                                            force_w=8, force_h=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 128, (128000, 256))\n",
      "loaded\n",
      "(128, 128, (128000, 256))\n",
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 16, 16)\n",
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 100000, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 800, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_b2, data, layers, w, h, c = load_model(\"../training/fractal/b2/model.pkl\", \n",
    "                                            dataset=\"random_cropped_digits\", \n",
    "                                            force_w=16, force_h=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 128, (128000, 256))\n",
      "loaded\n",
      "(128, 128, (128000, 256))\n",
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 9999999999, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 500, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_b3, data, layers, w, h, c = load_model(\"../training/fractal/b3/model.pkl\", \n",
    "                                            dataset=\"random_cropped_digits\", \n",
    "                                            force_w=16, force_h=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 9999999999, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 500, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_a2, data, layers, w, h, c = load_model(\"../training/fractal/a2/model.pkl\", \n",
    "                                            dataset=\"rescaled_digits\", \n",
    "                                            force_w=16, force_h=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 9999999999, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 500, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_a3, data, layers, w, h, c = load_model(\"../training/fractal/a3/model.pkl\", \n",
    "                                            dataset=\"rescaled_digits\", \n",
    "                                            force_w=16, force_h=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 9999999999, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 500, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_a4, data, layers, w, h, c = load_model(\"../training/fractal/a4/model.pkl\", \n",
    "                                            dataset=\"rescaled_digits\", \n",
    "                                            force_w=16, force_h=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patience_stat': 'avg_loss_train_fix', 'epsilon': 1e-08, 'max_nb_epochs': 9999999999, 'batch_size': 128, 'initial_lr': 0.1, 'patience_nb_epochs': 500, 'lr_decay_method': 'none', 'beta2': 0.95, 'beta1': 0.95, 'min_nb_epochs': 100000, 'lr_decay': 0, 'momentum': 0.9, 'algo': 'adadelta'}\n"
     ]
    }
   ],
   "source": [
    "model_a5, data, layers, w, h, c = load_model(\"../training/fractal/a5/model.pkl\", \n",
    "                                            dataset=\"rescaled_digits\", \n",
    "                                            force_w=16, force_h=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downscale(x, scale=2):\n",
    "    h, w = x.shape\n",
    "    x = x.reshape((h / scale, scale, w / scale, scale))\n",
    "    return x.mean(axis=(1, 3)), (x - x.mean(axis=(1, 3), keepdims=True)).reshape((h, w))\n",
    "\n",
    "def downscale_simple(x, scale=2):\n",
    "    h, w = x.shape\n",
    "    return x[::scale, ::scale]    \n",
    "    \n",
    "def upscale(x, r):\n",
    "    shape = r.shape\n",
    "    y_scale = r.shape[0] / x.shape[0]\n",
    "    x_scale = r.shape[1] / x.shape[1]        \n",
    "    r = r.reshape((r.shape[0] / y_scale, y_scale, r.shape[1] / x_scale, x_scale))\n",
    "    x = x.reshape((x.shape[0], 1, x.shape[1], 1))\n",
    "    return (x + r).reshape(shape)\n",
    "\n",
    "def upscale_simple(x, scale=2):\n",
    "    y = np.zeros((x.shape[0]*scale, x.shape[1]*scale))\n",
    "    y[::scale, ::scale] = x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_b1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4eb42d1457ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# BEGINS with b = trained on crops of digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m neuralnets = [\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_b1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'on'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'crops'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'padlen'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'nb_iter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'thresh'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'moving'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'when'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'always'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_a1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'on'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'crops'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'padlen'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'nb_iter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'thresh'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'moving'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'when'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'always'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_b1' is not defined"
     ]
    }
   ],
   "source": [
    "# BEGINS with a = trained on rescaled digits\n",
    "# BEGINS with b = trained on crops of digits\n",
    "neuralnets = [\n",
    "    {'model': model_b1, 'on': 'crops',  'padlen': 3,  'nb_iter': 1,  'thresh': 'moving', 'when': 'always'},\n",
    "    {'model': model_a1, 'on': 'crops',  'padlen': 3,  'nb_iter': 1, 'thresh': 'moving', 'when': 'always'},\n",
    "]\n",
    "whitepx_ratio = 0.5\n",
    "def gen(neuralnets, nb_iter=10, w=32, h=32, init='random'):    \n",
    "    out_img = np.random.uniform(size=(h, w)) if init == 'random' else init\n",
    "    snapshots = []\n",
    "    nb_full = 0\n",
    "    for i in range(nb_iter):\n",
    "        \n",
    "        #snapshots.append(out_img.copy())\n",
    "        \n",
    "        for nnet in neuralnets:\n",
    "            when = nnet.get('when', 'always')\n",
    "            if type(when) == list:\n",
    "                allow = False\n",
    "                for w in when:\n",
    "                    if type(w) == tuple:\n",
    "                        w1 = int(w[0] * nb_iter)\n",
    "                        w2 = int(w[1] * nb_iter)\n",
    "                        if (i >= w1 and i < w2):\n",
    "                            allow = True\n",
    "                    else:\n",
    "                        w = int(w*nb_iter)\n",
    "                        if i == w:\n",
    "                            allow = True    \n",
    "                if not allow:\n",
    "                    continue\n",
    "            model = nnet['model']\n",
    "            on = nnet['on']\n",
    "            patch_h, patch_w = model.layers['output'].output_shape[2:]\n",
    "            nb_iter_local = nnet.get('nb_iter', 10)\n",
    "            thresh = nnet.get('thresh', 0.5)\n",
    "            if on == 'crops':\n",
    "                padlen = nnet.get('padlen', 5) \n",
    "                img = pad(out_img, padlen, 'constant', constant_values=(0, 0))\n",
    "                py = np.random.randint(0, img.shape[0] - patch_h)\n",
    "                px = np.random.randint(0, img.shape[1] - patch_w)\n",
    "                patch = img[py:py + patch_h, px:px + patch_w]\n",
    "                patch = patch[np.newaxis, np.newaxis, :, :]\n",
    "                patch = patch.astype(np.float32)\n",
    "                noise = nnet.get('noise', 0)\n",
    "                for _ in range(nb_iter_local):\n",
    "                    if noise:patch *= np.random.uniform(size=patch.shape)<=(1-noise)\n",
    "                    patch = model.reconstruct(patch)\n",
    "                    \n",
    "                    if thresh == 'moving':\n",
    "                        vals = patch.flatten()\n",
    "                        vals = vals[np.argsort(vals)]\n",
    "                        thresh_ = vals[-int(whitepx_ratio * len(vals)) - 1]\n",
    "                    else:\n",
    "                        thresh_ = thresh\n",
    "                    if thresh: patch = patch > thresh_\n",
    "                    patch = patch.astype(np.float32)\n",
    "                img[py:py + patch_h, px:px + patch_w] = patch[0, 0]\n",
    "                out_img[:, :] = img[padlen:-padlen, padlen:-padlen]\n",
    "            elif on == 'full':\n",
    "                nb_full += 1\n",
    "                scale = h / model.layers['output'].output_shape[2]\n",
    "                #img, resid = downscale(out_img, scale=scale)\n",
    "                img = downscale_simple(out_img, scale=scale)\n",
    "                img = img[np.newaxis, np.newaxis, :, :]\n",
    "                img = img.astype(np.float32)\n",
    "                for _ in range(nb_iter_local):\n",
    "                    img = model.reconstruct(img)\n",
    "                    \n",
    "                    if thresh == 'moving':\n",
    "                        vals = img.flatten()\n",
    "                        vals = vals[np.argsort(vals)]\n",
    "                        thresh_ = vals[-int(whitepx_ratio * len(vals)) - 1]\n",
    "                    else:\n",
    "                        thresh_ = thresh\n",
    "\n",
    "                    if thresh:img = img > thresh_\n",
    "                    \n",
    "                img = img[0, 0]\n",
    "                #resid[:]=0\n",
    "                #print(img.shape)\n",
    "                img = upscale_simple(img, scale=scale)\n",
    "                #print(img.shape)\n",
    "\n",
    "                #img = normalize(img)\n",
    "                img = img > thresh_\n",
    "                img = img.astype(np.float32)\n",
    "                out_img = img\n",
    "    return out_img, snapshots\n",
    "imgs = []\n",
    "for i in range(1):\n",
    "    img, snap = gen(neuralnets, nb_iter=20000, w=2**9, h=2**9, init='random')\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACIAAAAiCAIAAAC1JZyVAAABHUlEQVR4nL1XWxLDIAgEJ8fLcXs/\n++EM4oL4qHY/Oo0Ca+QZfukfeIjoc85czhlWmPklSiD0I3rESf65QqeQNOc9PL0NZt44gWiB7lP2\ntC0QhUdAzrmox2LVNzNGLYq8q6XNpj3rQ8BVN5fWIxOd7dOksUjLZyPC5oOVaXwzmXR21/4KygUk\nOuoYl4PuhQDAT88Z1l5cuOsOzeSbxWKwuxZp27hFAyE6SzPTWshEmkhW30gt0BUhKM/g6riQd98m\nOPKSZE1PWOo9bkAsNAEddwS7Mt9BKo2rs5QcAS7mjfaZQ3OkvumqT3JpceNa6uJu1GFNs8ODzThr\nZZg6TuncmNmGKjjZnAIrUDAOblt31wc0p7oqTp2XujX/5zPqC+e+LXUQjAbXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "image/png": {
       "height": 100,
       "width": 100
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = disp_grid(np.array(imgs)[:, None, :, :], \n",
    "                border=1,\n",
    "                bordercolor=(0.3, 0, 0))\n",
    "imsave('out.png', img)\n",
    "Image('out.png', width=100, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-464b2fdf050e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq_to_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'out.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membed_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2c71830491bd>\u001b[0m in \u001b[0;36mseq_to_video\u001b[0;34m(seq, filename, verbose, framerate, rate, **kw)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# shape of seq should be : (examples, time, c, w, h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_grid_of_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "seq_to_video(np.array(snap)[np.newaxis, :, np.newaxis], 'out.mp4')\n",
    "embed_video('out.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sw, sh = 8, 8\n",
    "h, w = 16, 16\n",
    "scale = 2\n",
    "\n",
    "imgs = []\n",
    "np.random.seed(2)\n",
    "for K in range(25):\n",
    "    x = np.random.uniform(0, 1, size=(h*scale, w*scale))\n",
    "    #x = resize(data_orig.X[0].reshape((28, 28)), (32, 32))\n",
    "    nb_iter = 300\n",
    "    for i in range(nb_iter):\n",
    "\n",
    "        if i % (nb_iter/2) == 0 and i > 0:\n",
    "            # up\n",
    "            x_new, resid = downscale(x, scale=scale)\n",
    "            x_new = downscale_simple(x, scale=scale)\n",
    "            x_new = x_new[np.newaxis, np.newaxis, :, :]\n",
    "            x_new = x_new.astype(np.float32)\n",
    "\n",
    "            for _ in range(10):\n",
    "                \n",
    "                x_new = model_a1.reconstruct(x_new)\n",
    "                x_new = x_new > 0.48\n",
    "                x_new = x_new.astype(np.float32)\n",
    "\n",
    "            x_new = x_new[0, 0]\n",
    "            #resid[:]=0\n",
    "            x_new = upscale(x_new, resid)\n",
    "            #print(x_new.min(), x_new.max())\n",
    "            x  = x_new\n",
    "            x = x > 0.5\n",
    "\n",
    "        padlen = 3\n",
    "        x_ = pad(x, padlen, 'constant', constant_values=(0, 0))\n",
    "        \n",
    "        py = np.random.randint(0, x_.shape[0] - sh)\n",
    "        px = np.random.randint(0, x_.shape[0] - sw)\n",
    "        patch = x_[py:py+sh, px:px+sw]#.copy()\n",
    "        #print(x.shape, patch.shape)\n",
    "        patch = patch[np.newaxis, np.newaxis, :, :]\n",
    "        patch = patch.astype(np.float32)\n",
    "        \n",
    "        \n",
    "        for _ in range(1):\n",
    "            patch += np.random.uniform(0, 0.05, size=patch.shape)\n",
    "            patch = model_b1.reconstruct(patch)\n",
    "            patch = patch > 0.5\n",
    "            patch = patch.astype(np.float32)\n",
    "        x_[py:py+sh, px:px+sw] = patch[0, 0]\n",
    "        \n",
    "        x[:, :] = x_[padlen:-padlen, padlen:-padlen]\n",
    "        x = x > 0.5\n",
    "        #display.clear_output(wait=True)\n",
    "        #plt.imshow(x, cmap='gray', interpolation='none')\n",
    "        #display.display(plt.gcf())\n",
    "    imgs.append(x)\n",
    "#display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = disp_grid(np.array(imgs)[:, None, :, :], \n",
    "                border=1,\n",
    "                bordercolor=(0.3, 0, 0))\n",
    "imsave('out.png', img)\n",
    "Image('out.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFLCAIAAADQ1TnJAAA2oUlEQVR4nO1d2W0dOxJtAwqgAzBg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\nU4oQ1tz1TtgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.transform import rescale\n",
    "x = np.random.uniform(size=(10*10, 1, 16, 16)).astype(np.float32)\n",
    "iters = []\n",
    "thresh = 'moving'\n",
    "whitepx_ratio=0.4\n",
    "for i in range(10):\n",
    "    x  = model_b2.reconstruct(x)\n",
    "    \n",
    "    if thresh == 'moving':\n",
    "        vals = x.flatten()\n",
    "        vals = vals[np.argsort(vals)]\n",
    "        thresh_ = vals[-int(whitepx_ratio * len(vals)) - 1]\n",
    "    else:\n",
    "        thresh_ = thresh\n",
    "    x = x>thresh_\n",
    "    #x = np.random.uniform(size=x.shape)<=x\n",
    "    iters.append(x.copy())\n",
    "\n",
    "x_r = np.empty((x.shape[0], 1, 32, 32))\n",
    "for i in range(len(x)):\n",
    "    x_r[i, 0] = resize(x[i, 0], (32, 32))\n",
    "#x_r = x_r > t\n",
    "x_r = x_r.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3))\n",
    "img = dispims_color(x_r, border=1, bordercolor=(0.3, 0.0, 0.0))\n",
    "imsave('out.png', img)\n",
    "Image('out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove `out.mp4': No such file or directory\r\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e1bb01f5be28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'rm out.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimgs_to_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'out.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membed_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2c71830491bd>\u001b[0m in \u001b[0;36mdisp_grid\u001b[0;34m(imgs, **kw)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisp_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# shape of imgs should be : (examples, color, w, h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispims_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "!rm out.mp4\n",
    "iters = map(disp_grid, iters)\n",
    "imgs_to_video(iters, out='out.mp4', verbose=1, framerate=8, rate=8)\n",
    "embed_video('out.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = x.reshape((x.shape[0], -1))\n",
    "def hash_array(x):\n",
    "    return hash(tuple(x))\n",
    "h = map(hash_array, h)\n",
    "len(set(h)) / float(len(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
