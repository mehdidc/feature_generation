{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcherti/miniconda/envs/databoard-env/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "Using gpu device 0: Tesla K20Xm (CNMeM is disabled, cuDNN Version is too old. Update to v5, was 3007.)\n",
      "/home/mcherti/work/code/external/scikit-learn/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['THEANO_FLAGS'] = 'device=gpu'\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "\n",
    "from tasks import check as load_filename\n",
    "from scripts.imgtovideo import imgs_to_video\n",
    "from data import load_data\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lasagne import layers as L\n",
    "\n",
    "from lasagnekit.misc.plot_weights import dispims_color, tile_raster_images\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def load_model(filename, **kw):\n",
    "\n",
    "    model = load_filename(\n",
    "        what=\"notebook\", \n",
    "        filename=filename, \n",
    "        dataset='digits',\n",
    "        **kw\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_brush_func(layers):\n",
    "    \n",
    "    if 'biased_out' in layers:\n",
    "        bias = layers['biased_out'].b.get_value()\n",
    "    elif 'bias' in layers:\n",
    "        bias = layers['bias'].b.get_value()\n",
    "    else:\n",
    "        bias = 0\n",
    "    if 'scaled_out' in layers:\n",
    "        scale = layers['scaled_out'].scales.get_value()\n",
    "    else:\n",
    "        scale = 1\n",
    "    \n",
    "    X = T.tensor4()\n",
    "    fn = theano.function(\n",
    "        [X], \n",
    "        T.nnet.sigmoid(L.get_output(layers['brush'], X) * scale + bias)\n",
    "    )\n",
    "    return fn\n",
    "\n",
    "def build_encode_func(layers):\n",
    "    w = layers['output'].output_shape[2]\n",
    "    X = T.tensor4()\n",
    "    fn = theano.function(\n",
    "        [X], \n",
    "        T.nnet.sigmoid(L.get_output(layers['coord'], X)[:, :, 0:2]) * w\n",
    "    )\n",
    "    return fn\n",
    "\n",
    "def to_grid_of_images(seq_imgs):\n",
    "    y = seq_imgs\n",
    "    imgs = []\n",
    "    for t in range(y.shape[1]):\n",
    "        yy = y[:, t]\n",
    "        yy = yy[:, :, :, None] * np.ones((1, 1, 1, 3))\n",
    "        img = dispims_color(yy, border=0)\n",
    "        imgs.append(img)\n",
    "    return imgs\n",
    "\n",
    "def seq_to_video(seq, filename='out.mp4', verbose=1, framerate=8, rate=8):\n",
    "    # shape of seq should be : (examples, time, w, h) or (examples, time, 1, w, h)\n",
    "    if len(seq.shape) == 5:\n",
    "        seq = seq[:, :, 0, :, :]\n",
    "    seq = to_grid_of_images(seq)\n",
    "    seq = [np.zeros_like(seq[0])] + seq\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    imgs_to_video(seq, out=filename, verbose=verbose, framerate=framerate, rate=rate)\n",
    "\n",
    "def embed_video(filename):\n",
    "    video = open(filename, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                </video>'''.format(encoded.decode('ascii')))\n",
    "def disp_grid(imgs, **kw):\n",
    "    # shape of imgs should be : (examples, color, w, h)\n",
    "    out = dispims_color(imgs.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3)), **kw)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and build functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-83e4918475b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m model, data, layers, w, h, c = load_model('../training/brush11/model.pkl',\n\u001b[0;32m     11\u001b[0m                                           \u001b[1;31m#force_model_params={'w_out': 112, 'h_out': 112},\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                                           kw_load_data={'include_test': True})\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-fdea0d67c414>\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filename, **kw)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'digits'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mcherti/miniconda/envs/databoard-env/lib/python2.7/site-packages/invoke/tasks.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Contextualized task expected a Context, got {0} instead!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes_called\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mcherti/work/code/feature_generation/ipynb/../tasks.pyc\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(filename, what, dataset, prefix, force_w, force_h, force_c, params, folder, update_db, batch_size, kw_load_data, force_model_params)\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforce_h\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#if h not specified take the one in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mcherti/work/code/feature_generation/ipynb/../tasks.pyc\u001b[0m in \u001b[0;36mload_\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    816\u001b[0m         builder, kw_builder, values = (\n\u001b[0;32m    817\u001b[0m             data[\"builder\"], data[\"kw_builder\"], data[\"values\"])\n",
      "\u001b[1;32m/home/mcherti/miniconda/envs/databoard-env/lib/python2.7/site-packages/dill/dill.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[0mpik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[0mpik\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_main\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_main_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpik\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_main_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# point obj class to main\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpik\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mcherti/miniconda/envs/databoard-env/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mcherti/miniconda/envs/databoard-env/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_eof\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# some selected models :\n",
    "# 1) ../training/brush7/model.pkl\n",
    "# 2) ../jobs/results/df2631577eaf38b002c6c0ae6f1937e1/model.pkl \n",
    "# 3) ../jobs/results/68fa4141b9f970f6bde95da53b8e54fe/model.pkl \n",
    "# 4) ../jobs/results/88b68a0c06bfb0a837cf7c0b77fe7eb9/model.pkl \n",
    "# 5) ../jobs/results/9c70a6ee9340c85b398a31f7d16be962/model.pkl\n",
    "# 6) ../jobs/results/bc8b5c4156561f4f09685874d52ba20e/model.pkl\n",
    "# 7) ../jobs/results/a50c86acf5a2875dda6e1ac5b8d462c1/model.pkl\n",
    "# 8) ../training/brush9/model.pkl\n",
    "model, data, layers, w, h, c = load_model('../training/brush11/model.pkl',\n",
    "                                          #force_model_params={'w_out': 112, 'h_out': 112},\n",
    "                                          kw_load_data={'include_test': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(model.hypers['model_params'], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode = build_encode_func(layers) # transforms image to sequence of coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brush = build_brush_func(layers) # transforms an image to sequence of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruct = model.reconstruct # reconstructs an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get coords from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode(model.preprocess(data.X[0:10])).shape # (examples, time, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = brush(model.preprocess(data.test.X[0:11*11])) # (examples, time, w, h)\n",
    "print(imgs.shape)\n",
    "seq_to_video(imgs, 'seq.mp4')\n",
    "embed_video('seq.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(reconstruct(model.preprocess(data.test.X[0:100]))), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterative refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_iter = 500\n",
    "nb_examples = 100\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "imgs = np.empty((nb_examples, nb_iter + 1, 1, w, h)) # 1 = color channel\n",
    "imgs = imgs.astype(np.float32)\n",
    "\n",
    "imgs[:, 0] = np.random.uniform(size=(nb_examples, 1, w, h))\n",
    "for i in tqdm(range(1, nb_iter + 1)):\n",
    "    imgs[:, i] = reconstruct(imgs[:, i - 1])\n",
    "    imgs[:, i] = imgs[:, i] > 0.5 # binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(imgs[:, -1])) # display last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_to_video(imgs, 'ir.mp4')\n",
    "embed_video('ir.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strokes = load_data('strokes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# load from file\n",
    "\n",
    "\"\"\"\n",
    "img = imread('4Tbx4rALc.jpeg')\n",
    "img = img[:, :, 0]\n",
    "img = resize(img, (w, h), preserve_range=True)\n",
    "img = img.astype(np.float32)\n",
    "img /= 255.\n",
    "img = 1 - img\n",
    "\"\"\"\n",
    "\n",
    "# dataset of strokes\n",
    "\n",
    "nb = 100\n",
    "dt = strokes.X[0:nb].reshape((nb, 1, w, h))\n",
    "\n",
    "rec = dt.copy()\n",
    "rec = reconstruct(rec)\n",
    "#rec = rec > 0.3\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(dt, bordercolor=(200, 200, 200), border=1), cmap='gray')\n",
    "plt.title('original')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(rec,  bordercolor=(200, 200, 200), border=1), cmap='gray')\n",
    "plt.title('reconstruction')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
