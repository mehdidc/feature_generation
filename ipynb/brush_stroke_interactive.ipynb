{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu'\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "\n",
    "from tasks import check as load_filename\n",
    "from scripts.imgtovideo import imgs_to_video\n",
    "from data import load_data\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lasagne import layers as L\n",
    "\n",
    "from lasagnekit.misc.plot_weights import dispims_color, tile_raster_images\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def load_model(filename, **kw):\n",
    "\n",
    "    model = load_filename(\n",
    "        what=\"notebook\", \n",
    "        filename=filename, \n",
    "        **kw\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_brush_func(layers):\n",
    "    if 'biased_output' in layers:\n",
    "        bias = layers['biased_output'].b.get_value()\n",
    "    elif 'bias' in layers:\n",
    "        bias = layers['bias'].b.get_value()\n",
    "    else:\n",
    "        bias = np.array(0.1)\n",
    "\n",
    "    bias = bias[np.newaxis, np.newaxis, :, np.newaxis, np.newaxis]\n",
    "\n",
    "    if 'scaled_output' in layers:\n",
    "        scale = layers['scaled_output'].scales.get_value()\n",
    "    elif 'scale' in layers:\n",
    "        scale = layers['scale'].scales.get_value()\n",
    "    else:\n",
    "        scale = np.array(1.)\n",
    "\n",
    "    scale = scale[np.newaxis, np.newaxis, :, np.newaxis, np.newaxis]\n",
    "\n",
    "\n",
    "    X = T.tensor4()\n",
    "    fn = theano.function(\n",
    "        [X], \n",
    "        T.nnet.sigmoid(L.get_output(layers['brush'], X) * scale + bias)\n",
    "    )\n",
    "    return fn\n",
    "\n",
    "def build_encode_func(layers):\n",
    "    w = layers['output'].output_shape[2]\n",
    "    X = T.tensor4()\n",
    "    fn = theano.function(\n",
    "        [X], \n",
    "        T.nnet.sigmoid(L.get_output(layers['coord'], X)[:, :, 0:2]) * w\n",
    "    )\n",
    "    return fn\n",
    "\n",
    "def to_grid_of_images(seq_imgs):\n",
    "    y = seq_imgs\n",
    "    imgs = []\n",
    "    for t in range(y.shape[1]):\n",
    "        yy = y[:, t]\n",
    "        if yy.shape[1] == 1:\n",
    "            yy = yy[:, 0, :, :, None] * np.ones((1, 1, 1, 3))\n",
    "        else:\n",
    "            yy = yy.transpose((0, 2, 3, 1))\n",
    "        img = dispims_color(yy, border=1, bordercolor=(0.3, 0.3, 0.3))\n",
    "        imgs.append(img)\n",
    "    return imgs\n",
    "\n",
    "def seq_to_video(seq, filename='out.mp4', verbose=1, framerate=8, rate=8):\n",
    "    # shape of seq should be : (examples, time, c, w, h)\n",
    "    seq = to_grid_of_images(seq)\n",
    "    seq = [np.zeros_like(seq[0])] + seq\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    imgs_to_video(seq, out=filename, verbose=verbose, framerate=framerate, rate=rate)\n",
    "\n",
    "def embed_video(filename):\n",
    "    video = open(filename, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                </video>'''.format(encoded.decode('ascii')))\n",
    "def disp_grid(imgs, **kw):\n",
    "    # shape of imgs should be : (examples, color, w, h)\n",
    "    out = dispims_color(imgs.transpose((0, 2, 3, 1)) * np.ones((1, 1, 1, 3)), **kw)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and build functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some selected models :\n",
    "models = [\n",
    "    \"../training/brush7/model.pkl\", #0 \n",
    "    \"../jobs/results/df2631577eaf38b002c6c0ae6f1937e1/model.pkl\", #1\n",
    "    \"../jobs/results/68fa4141b9f970f6bde95da53b8e54fe/model.pkl\", #2\n",
    "    \"../jobs/results/88b68a0c06bfb0a837cf7c0b77fe7eb9/model.pkl\", #3\n",
    "    \"../jobs/results/9c70a6ee9340c85b398a31f7d16be962/model.pkl\", #4\n",
    "    \"../jobs/results/bc8b5c4156561f4f09685874d52ba20e/model.pkl\", #5\n",
    "    \"../jobs/results/a50c86acf5a2875dda6e1ac5b8d462c1/model.pkl\", #6\n",
    "    \"../training/brush9/model.pkl\", #7\n",
    "    \"../jobs/results/76f2a5320d2d700ee5943dceb2c3e004/model.pkl\", #8\n",
    "    \"../jobs/results/b38bd0e4e6ac281e6eba581cbe9d62d3/model.pkl\", #9\n",
    "    \"../training/brush12/model.pkl\", #10\n",
    "    \"../jobs/results/8af0f0ff67a2c27a4bede27a9867c5cc/model.pkl\", #11\n",
    "    \"../jobs/results/8fbec06424d9cae3887acf14bc01948b/model.pkl\" #12\n",
    "    \"../training/brush16/model.pkl\"#13\n",
    "]\n",
    "\n",
    "#0  : (mnist:nice,                   ir:emptyfixated,         strokes:bad)\n",
    "#1  : (mnist:nice and curvy,         ir:noisy blobs,          strokes:very_bad and blurry)\n",
    "#2  : (mnist:ok but a bit blurry,    ir:nice,                 strokes:bad and blurry)\n",
    "#3  : (mnist:very nice but probs,    ir:noisy points,         strokes:bad but not blurry)\n",
    "#4  : (mnist:very nice but blurBlo,  ir:emptyfixated,         strokes:bad but not blurry)\n",
    "#5  : (mnist:very nice and squary,   ir:emptyfixated,         strokes:okayish)\n",
    "#6  : (mnist:very nice and squary,   ir:emptyfixated,         strokes:okayish)\n",
    "#7  : (mnist:very nice and squary,   ir:emptyfixated,         strokes:okayish)\n",
    "#8  : (mnist:almostperfect,          ir:digits_fixatedone,    strokes:bad)\n",
    "#9  : (mnist:almostperfect,          ir:digits_fixatedone,    strokes:bad)\n",
    "#10 : (mnist:almostperfect,          ir:emptyfixated,         strokes:okayish)\n",
    "#11 : (mnist:ok but a blurry,        ir:nice  but blobby,     strokes:bad and blurry)\n",
    "#12 : (mnist:nice,                   ir:nice but fixated,     strokes:bad but not blurry)\n",
    "#13 : (omniglot:nice,                ir:strokesfixated,       strokes:ok)\n",
    "filename = np.random.choice(models)\n",
    "model, data, layers, w, h, c = load_model(\"../training/brush20/model.pkl\",\n",
    "                                          #force_w=64,\n",
    "                                          #force_h=64,\n",
    "                                          dataset='aloi',\n",
    "                                          #force_model_params={'w_out': 128, 'h_out': 128},\n",
    "                                          kw_load_data={'include_test': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(json.dumps(model.hypers['model_params'], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode = build_encode_func(layers) # transforms image to sequence of coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brush = build_brush_func(layers) # transforms an image to sequence of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruct = model.reconstruct # reconstructs an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get coords from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode(model.preprocess(data.X[0:10])).shape # (examples, time, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = brush(model.preprocess(data.X[0:11*11])) # (examples, time, w, h)\n",
    "seq_to_video(imgs, 'seq.mp4')\n",
    "embed_video('seq.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(model.preprocess(data.X[0:100])), cmap='gray', interpolation='none')\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(reconstruct(model.preprocess(data.X[0:100]))), cmap='gray', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterative refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_iter = 100\n",
    "nb_examples = 100\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "imgs = np.empty((nb_examples, nb_iter + 1, c, w, h)) # 1 = color channel\n",
    "imgs = imgs.astype(np.float32)\n",
    "\n",
    "imgs[:, 0] = np.random.uniform(size=(nb_examples, c, w, h))\n",
    "noise = np.random.normal(0, 0.5, size=imgs[:, 0].shape).astype(np.float32) #(for colored images)\n",
    "#noise = 0\n",
    "\n",
    "for i in tqdm(range(1, nb_iter + 1)):\n",
    "    imgs[:, i] = reconstruct(imgs[:, i - 1] + noise)\n",
    "    #imgs[:, i] = imgs[:, i] > 0.5 # binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(imgs[:, -1])) # display last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_to_video(imgs, 'ir.mp4')\n",
    "embed_video('ir.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_test = load_data('strokes', w=w,h=h) # for grayscale\n",
    "#dt_test = load_data('digits', w=w, h=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# load from file\n",
    "\n",
    "\n",
    "nb = 100\n",
    "dt = dt_test.X[0:nb]\n",
    "try:\n",
    "    dt = dt.reshape((nb, c, w, h))\n",
    "except Exception:\n",
    "    dt = dt.reshape((nb, 1, w, h))\n",
    "    dt = dt * np.ones((1, 3, 1, 1))\n",
    "    dt = dt.astype(np.float32)\n",
    "print(dt.shape)\n",
    "rec = reconstruct(dt)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(dt, bordercolor=(200, 200, 200), border=1), cmap='gray')\n",
    "plt.title('original')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(disp_grid(rec,  bordercolor=(200, 200, 200), border=1), cmap='gray')\n",
    "plt.title('reconstruction')\n",
    "plt.show()\n",
    "print(((rec - dt)**2).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
