{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcherti/work/code/external/scikit-learn/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/mcherti/miniconda/envs/databoard-env/lib/python2.7/site-packages/matplotlib/__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "from tools.system.imgtovideo import imgs_to_video\n",
    "from data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers as L\n",
    "from lasagnekit.misc.plot_weights import dispims_color, tile_raster_images\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "\n",
    "\n",
    "from tools.brushstroke.common import (\n",
    "    resize_set, load_model, get_bias, \n",
    "    get_scale, build_brush_func,\n",
    "    build_encode_func,\n",
    "    build_image_to_code_func,\n",
    "    build_code_to_image,\n",
    "    to_grid_of_images,\n",
    "    seq_to_video,\n",
    "    embed_video,\n",
    "    disp_grid,\n",
    "    prop_uniques,\n",
    "    hash_array,\n",
    "    normalize,\n",
    "    sigmoid,\n",
    "    build_pointer_images)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def accumulate(X, fn):\n",
    "    for t in range(1, X.shape[1]):\n",
    "        X[:, t] = fn(X[:, t], X[:, t - 1])\n",
    "    return X\n",
    "\n",
    "def mask_op(new, prev, eps=0.1):\n",
    "    img1 = prev\n",
    "    img2 = new\n",
    "    a2 = 1 - (np.abs(img2[:,0])<eps) * (np.abs(img2[:,1])<eps) * (np.abs(img2[:,2])<eps)   \n",
    "    a2=a2[:,None, :, :]\n",
    "    img = img1 * (1 - a2) + img2 * a2\n",
    "    return img\n",
    "\n",
    "def smooth_mask_op(new, prev):\n",
    "    img1 = prev\n",
    "    img2 = new\n",
    "    a2 = new.mean(axis=1, keepdims=True)\n",
    "    img = img1 * (1 - a2) + img2 * a2\n",
    "    return img\n",
    "\n",
    "def softmax(x):\n",
    "    x = np.exp(x)\n",
    "    return x / x.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and build functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Loading the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tasks:Compiling the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"n_steps\": 1, \n",
      "  \"nb_colors\": 8, \n",
      "  \"stride\": [\n",
      "    0.25, \n",
      "    1\n",
      "  ], \n",
      "  \"patch_size\": 16, \n",
      "  \"proba_func\": \"softmax\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model, data, layers = load_model(\"../training/brush/unit_tests/006/model.pkl\")\n",
    "w, h = layers['output'].output_shape[2:]\n",
    "print(json.dumps(model.hypers['model_params'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_parallel = model.hypers['model_params'].get('parallel', 1)\n",
    "coord_layers = [l for l in layers.keys() if 'coord' in l]\n",
    "brush_layers = [l for l in layers.keys() if 'brush' in l]\n",
    "coord = coord_layers[0]\n",
    "brush = brush_layers[0]\n",
    "X = T.tensor4()\n",
    "C = T.tensor3()    \n",
    "get_brushes = theano.function(\n",
    "    [X], \n",
    "    L.get_output(layers[brush], X))\n",
    "encoders = []\n",
    "for c in coord_layers:\n",
    "    encoder = build_encode_func(layers, lay=c)\n",
    "    encoders.append(encoder)\n",
    "get_reprs = []\n",
    "for c in coord_layers:\n",
    "    get_reprs.append(theano.function([X], L.get_output(layers[c], X)))\n",
    "\n",
    "get_repr = theano.function([X], L.get_output(layers[coord], X))\n",
    "get_brush = build_brush_func(\n",
    "    layers, \n",
    "    lay=brush_layers,\n",
    "    nonlin=lambda x:x) # transforms an image to sequence of imagess\n",
    "reconstruct = model.reconstruct # reconstructs an image\n",
    "\n",
    "scale = get_scale(layers)\n",
    "\n",
    "bias = get_bias(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_brush = build_brush_func(\n",
    "    layers, \n",
    "    lay=brush_layers,\n",
    "    nonlin=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2code = build_image_to_code_func(layers, lay=tuple(coord_layers))\n",
    "tensors = tuple([T.tensor3() for _ in range(len(coord_layers))])\n",
    "code2img = build_code_to_image(layers, X=tensors, lay=tuple(coord_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'biased_resid_output' in layers:\n",
    "    X = T.tensor4()\n",
    "    get_resid = theano.function([X], L.get_output(layers['biased_resid_output'], X))\n",
    "    get_out = theano.function([X], L.get_output(layers['biased_output'], X))\n",
    "    get_raw_out = theano.function([X], L.get_output(layers['raw_output'], X))\n",
    "    get_out_from_raw_out = theano.function([X], L.get_output(layers['output'], {layers['raw_output']:X}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.load()\n",
    "X = model.preprocess(data.X[0:10*10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x:'{:.4f}'.format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f529b23be50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD9CAYAAAC8y8IrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxDkEzBLnEDBLnEPALHEOAbPE/R9lQqSvMy8C8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52883a4910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = (  (layers['brush'].colors_.get_value()) * 0.5 *  scale.flatten() + bias.flatten())\n",
    "img = img[:, :, None, None] * np.ones((1, 3, 12, 12))\n",
    "img = disp_grid(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'color': (6, 14), 'gx': 0, 'gy': 1, 'x_stride': (2, 4), 'y_stride': (4, 6)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers['brush'].assign_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5015, 0.5101, 0.5022, 0.5179, 0.5057, 0.5067, 0.5044, 0.5058,\n",
       "       0.5112, 0.5022, 0.5028, 0.5152, 0.5122, 0.5042, 0.5030, 0.4997,\n",
       "       0.5123, 0.5055, 0.5107, 0.5015, 0.5114, 0.5007, 0.5049, 0.5088,\n",
       "       0.5139, 0.5009, 0.5098, 0.5161, 0.5013, 0.5102, 0.5025, 0.5043,\n",
       "       0.5051, 0.5140, 0.5030, 0.5005, 0.5103, 0.5014, 0.5034, 0.5029,\n",
       "       0.5065, 0.5061, 0.4991, 0.5105, 0.5011, 0.5137, 0.5045, 0.5063,\n",
       "       0.5108, 0.5111, 0.4996, 0.5013, 0.5027, 0.5021, 0.5134, 0.5011,\n",
       "       0.5083, 0.5040, 0.4997, 0.5003, 0.5010, 0.5045, 0.5037, 0.5023,\n",
       "       0.5093, 0.5018, 0.5029, 0.5052, 0.5012, 0.5079, 0.5046, 0.5027,\n",
       "       0.5067, 0.5088, 0.5087, 0.5021, 0.5150, 0.5061, 0.5022, 0.5220,\n",
       "       0.5328, 0.5107, 0.5222, 0.5135, 0.5036, 0.5023, 0.5044, 0.5037,\n",
       "       0.5071, 0.5015, 0.5017, 0.5123, 0.5097, 0.5045, 0.5142, 0.5120,\n",
       "       0.5039, 0.5049, 0.5076, 0.5068])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(sigmoid(r[:, 0, 2:4]), [0.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5542 0.0117 0.0283]\n"
     ]
    }
   ],
   "source": [
    "codes = img2code(X)\n",
    "r = codes[0]\n",
    "def is_max(x):\n",
    "    m = x.max(axis=1, keepdims=True)\n",
    "    return (softmax(x) * (x==m))\n",
    "c = np.dot(softmax(r[:, 0, 6:14]), (layers['brush'].colors_.get_value())  )\n",
    "c = c * 0.5 * scale.flatten() + bias.flatten()\n",
    "print(c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABIAAAASCAIAAADZrBkAAAAAgklEQVR4nGP0YSALkKHNh4GBiTzL\nRrUNsDYWItWxsrJKSUmxsbExMDAw3L5NbCpRUlI8cuTQmzcv37x56UO8bezsHDo6Ovz8ghAuCX5j\nZESwidX28+fP69dvfPz4/uPH9wwMDIw+DAxbiNDGysoqKyvLzs7OwMCgfP06mRmHkbxsCgDEexwA\nm1cynwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "image/png": {
       "height": 400,
       "width": 400
      }
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f529e1ac390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import Normalize, NoNorm\n",
    "b, = get_brush(X)\n",
    "b = (b* scale + bias)\n",
    "b = np.clip(b, 0, 1)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "imsave('imgs/b.png', \n",
    "       disp_grid(b[3:4, 0], border=1, bordercolor=(0.3,0,0))\n",
    ")\n",
    "Image('imgs/b.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codes = img2code(X)\n",
    "r = codes[0]\n",
    "img = code2img(*codes)\n",
    "img = disp_grid(img, border=1, bordercolor=(0.3,0.3,0.3))\n",
    "imsave('imgs/im.png', img)\n",
    "Image('imgs/im.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a sequence with the enhancement module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_seq(X):\n",
    "    seq = []\n",
    "    feat = img2code(X)\n",
    "    for t in range(layers[coord_layers[0]].output_shape[1]):\n",
    "        feat_ = [f.copy() for f in feat]\n",
    "        for f in feat_:\n",
    "            f[:,t+1:]=-100\n",
    "        img = code2img(*feat_)\n",
    "        seq.append(img)\n",
    "    return seq\n",
    "\n",
    "seq = construct_seq(X)\n",
    "seq = np.array(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_ = np.array(seq[:])\n",
    "seq_ = seq.transpose((1, 0, 2, 3, 4))\n",
    "seq_to_video(seq_, 'vids/refined_seq.mp4')\n",
    "embed_video('vids/refined_seq.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get coords from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codes = []\n",
    "for encoder in get_reprs:\n",
    "    code = encoder(X)\n",
    "    codes.append(code)\n",
    "cols = [(1, 0, 0), (0, 1, 0), (0, 0, 1), (1, 1, 0), (1, 0, 1), (0, 1, 1)]\n",
    "cols = cols + cols\n",
    "print(model.hypers['model_params']['patch_size'])\n",
    "pointers = []\n",
    "for i, code in enumerate(codes):\n",
    "    if 'x_stride' in layers['brush_0'].assign_:\n",
    "        print(code.shape)\n",
    "        sx = sigmoid(code[:,:, layers['brush_0'].assign_['x_stride']]) * model.hypers['model_params']['patch_size']\n",
    "    else:\n",
    "        sx = None    \n",
    "\n",
    "    if 'y_stride' in layers['brush_0'].assign_:\n",
    "        sy = sigmoid(code[:,:, layers['brush_0'].assign_['y_stride']]) * model.hypers['model_params']['patch_size']\n",
    "    else:\n",
    "        sy = None\n",
    "    pointer = build_pointer_images(code[:, :, 0:2], cols[i], w, h, sx=sx, sy=sy, p=1)\n",
    "    pointers.append(pointer)\n",
    "pointers = sum(pointers)\n",
    "seq_to_video(pointers, 'vids/pointers.mp4')\n",
    "embed_video('vids/pointers.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video of gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = get_repr(X)\n",
    "draw(r)\n",
    "plt.plot(sigmoid(r[0, :, 12])*2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(disp_grid(layers['brush_0'].patches_.get_value()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs = get_brush(X) # (examples, time, c, w, h)\n",
    "imgs = sum(imgs)\n",
    "##imgs = accumulate(imgs, lambda a,b:a+b)\n",
    "imgs = imgs * scale + bias\n",
    "\n",
    "imgs = imgs\n",
    "#imgs = sigmoid(imgs)\n",
    "#imgs = 1-sigmoid(imgs)\n",
    "#imgs = imgs #+ pointers * (1-imgs)\n",
    "seq_to_video(imgs, 'vids/seq.mp4', framerate=1, rate=1)\n",
    "embed_video('vids/seq.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,20))\n",
    "d = imgs[:,-1].copy()\n",
    "d = disp_grid(d)\n",
    "ax1.set_axis_off()\n",
    "ax1.imshow(d)\n",
    "m = get_resid(X)\n",
    "d = ( ((get_resid(X)+get_out(X)))*0.5     )\n",
    "#d = 1-sigmoid(d)\n",
    "d = normalize(d, axis=0)\n",
    "d = disp_grid(d)\n",
    "ax2.set_axis_off()\n",
    "ax2.imshow(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im1 = disp_grid(model.preprocess(data.X[0:100]), border=1, bordercolor=(.3, .3, .3))\n",
    "r  = model.reconstruct(model.preprocess(data.X[0:100]))\n",
    "im2 = disp_grid(r, border=1, bordercolor=(.5, 0, 0))\n",
    "im_mix = np.empty(( max(im1.shape[0], im2.shape[0]), im1.shape[1] + im2.shape[1], 3))\n",
    "im_mix[0:im1.shape[0], 0:im1.shape[1]] = im1\n",
    "im_mix[0:im2.shape[0], im1.shape[1]:] = im2\n",
    "imsave('imgs/im_mix.png', im_mix)\n",
    "Image('imgs/im_mix.png', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.draw import circle\n",
    "texture = imread('imgs/metal_rust_texture_05_by_fantasystock.jpg')/255.\n",
    "S = 4\n",
    "x = 200\n",
    "patches = np.zeros((1, 3, 7*S, 7*S))\n",
    "ph, pw = patches.shape[2:]\n",
    "rr, cc = circle(ph/2, pw/2, S*3)    \n",
    "patches[:, :, rr, cc] = 1\n",
    "plt.imshow(patches[0,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = get_repr(X)\n",
    "\n",
    "from skimage.draw import circle\n",
    "\n",
    "def sharpen_draw_single(gx, gy, patch, col, w_out, h_out, img=None, mask=None):\n",
    "    c = patch.shape[0]\n",
    "    ph = patch.shape[1]\n",
    "    pw = patch.shape[2]\n",
    "    if img is  None:\n",
    "        img = np.zeros((c, w_out, h_out))\n",
    "        mask = np.zeros((c, w_out, h_out))\n",
    "    shape = img[:, gy:gy+ph, gx:gx+pw].shape\n",
    "    \n",
    "    n = patch[:, :shape[1], :shape[2]] * col[:, None, None]\n",
    "    mask_n = (1 - (n[0]==0) * (n[1]==0) * (n[2]==0))\n",
    "    o =   img[:, gy:gy+ph, gx:gx+pw]\n",
    "    mask_o = (1 - (o[0]==0) * (o[1]==0) * (o[2]==0))\n",
    "    img[:, gy:gy+ph, gx:gx+pw] = n * mask_n + o * (1 - mask_n) \n",
    "    img[:, gy:gy+ph, gx:gx+pw] = n * 0.5 + o * 0.5 \n",
    "    \n",
    "    return img\n",
    "\n",
    "def sharpen_draw(r, S=8):\n",
    "    \n",
    "    if 'patch_index' in layers['brush'].assign_:\n",
    "        patch_indices = layers['brush'].assign_['patch_index']\n",
    "    else:\n",
    "        patch_indices = None\n",
    "    if 'color' in layers['brush'].assign_:\n",
    "        color_indices = layers['brush'].assign_['color']\n",
    "    else:\n",
    "        color_indices = None\n",
    "    patches = layers['brush'].patches_.get_value()\n",
    "    ph, pw = patches.shape[2:]    \n",
    "    ph, pw = patches.shape[2:]\n",
    "    rr, cc = circle(ph/2, pw/2, S*3)    \n",
    "    #patches[:, :, rr, cc] = 1\n",
    "    #patches[:] *= texture.transpose((2, 0, 1))[:, 100:100+ph, 100:100+pw]\n",
    "    w_out = w * S\n",
    "    h_out = h * S\n",
    "    \n",
    "    c = patches.shape[1]\n",
    "    imgs = np.zeros((r.shape[0], c, h_out, w_out))\n",
    "    masks = np.zeros_like(imgs)\n",
    "\n",
    "    for t in range(r.shape[1]):\n",
    "        rt = r[:, t]\n",
    "        if patch_indices:\n",
    "            patch_index = rt[:, slice(*patch_indices)].argmax(axis=1)\n",
    "        else:\n",
    "            patch_index = np.zeros((rt.shape[0],))\n",
    "        if color_indices:\n",
    "            color = (rt[:, slice(*color_indices)])\n",
    "            color = sigmoid(color)\n",
    "        else:\n",
    "            color = np.ones((rt.shape[0], layers['output'].output_shape[1]))\n",
    "        for i in range(imgs.shape[0]):\n",
    "            gx = int(sigmoid(rt[i, 0]) * w_out)\n",
    "            gy = int(sigmoid(rt[i, 1]) * h_out)\n",
    "            sharpen_draw_single(gx, gy, patches[patch_index[i]], color[i], w_out, h_out, img=imgs[i], mask=masks[i])\n",
    "    return imgs\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "imgs = sharpen_draw(r, S=1)\n",
    "imgs = imgs * scale[0] + bias[0]\n",
    "imgs = 1-sigmoid(imgs)\n",
    "img = disp_grid(imgs)\n",
    "imsave('imgs/sharpen.png', img)\n",
    "Image('imgs/sharpen.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterative refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.random.seed(22)\n",
    "nb_iter = 200\n",
    "nb_examples = 100\n",
    "thresh = None\n",
    "use_noise = True\n",
    "learning_rate = 1\n",
    "c = layers['output'].output_shape[1]\n",
    "# PREP\n",
    "if thresh == 'moving':\n",
    "    whitepx_ratio = (data.X>0.5).sum() / np.ones_like(data.X).sum()\n",
    "\n",
    "imgs = np.empty((nb_examples, nb_iter + 1, c, w, h)) # 1 = color channel\n",
    "imgs = imgs.astype(np.float32)\n",
    "imgs[:, 0] = np.random.uniform(size=(nb_examples, c, w, h))\n",
    "\n",
    "if use_noise: noise = np.random.normal(0, 0.001, size=imgs[:, 0].shape).astype(np.float32) #(for colored images)\n",
    "else: noise = 0\n",
    "\n",
    "scores = []\n",
    "diversities = []\n",
    "\n",
    "# ITERATIOn\n",
    "\n",
    "for i in tqdm(range(1, nb_iter + 1)):\n",
    "    \n",
    "    if use_noise:noise = np.random.normal(0, 0.001, size=imgs[:, 0].shape).astype(np.float32) #(for colored images)\n",
    "    else:noise = 0\n",
    "    \n",
    "    new = model.reconstruct(imgs[:, i - 1] + noise)\n",
    "    prev = imgs[:, i - 1] \n",
    "    imgs[:, i] = new * learning_rate + prev * (1-learning_rate)\n",
    "    if c == 1:\n",
    "        if thresh == 'moving':\n",
    "            vals = imgs[:, i].flatten()\n",
    "            vals = vals[np.argsort(vals)]\n",
    "            thresh_ = vals[-int(whitepx_ratio * len(vals)) - 1]\n",
    "        else:\n",
    "            thresh_ = thresh\n",
    "        if thresh_:\n",
    "            imgs[:, i] = imgs[:, i] > thresh_ # binarize\n",
    "    score = np.abs(imgs[:, i - 1] - imgs[:, i]).sum()\n",
    "    scores.append(score)\n",
    "    diversity = prop_uniques(imgs[:, i])\n",
    "    diversities.append(diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check nearest neighbors in dataset of the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = -1\n",
    "nb_neighb = 10\n",
    "generated = imgs[:, T].copy()\n",
    "generated = normalize(generated, axis=(2, 3))\n",
    "dataset = data.X\n",
    "def euc(x, y):\n",
    "    return ((x-y)**2).mean(axis=(2, 3, 4))\n",
    "dist = euc\n",
    "neighb = (dist(generated[:, None], dataset[None, :])).argsort(axis=1)\n",
    "neighb = neighb[:, 0:nb_neighb]\n",
    "shape = neighb.shape\n",
    "neighb = neighb.flatten()\n",
    "neighb = dataset[neighb]\n",
    "neighb = neighb.reshape((shape[0], shape[1], c, h, w))\n",
    "neighb = np.concatenate((generated[:, None], neighb), axis=1)\n",
    "img = np.empty(( shape[0]*h, shape[1] *w, c))\n",
    "for y in range(shape[0]):\n",
    "    for x in range(shape[1]):\n",
    "        img[y*h:y*h+h, x*w:x*w+w] = neighb[y,x].transpose((1, 2, 0))\n",
    "        \n",
    "        img[y*h:y*h+h, x*w:x*w+1]=0.3 if x>1 else 1\n",
    "        img[y*h:y*h+1, x*w:x*w+w+1]=0.3 if x>0 else 1\n",
    "         \n",
    "imsave('imgs/neigh.png', img[:,:,0] if c==1 else img)\n",
    "Image('imgs/neigh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "img = disp_grid(imgs[:, -1], border=1, bordercolor=(0.3, 0, 0))\n",
    "imsave('imgs/ir.png', img)\n",
    "Image('imgs/ir.png', width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq_to_video(imgs, 'vids/ir.mp4', border=0, bordercolor=(0, 0, 0))\n",
    "embed_video('vids/ir.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Score')\n",
    "plt.plot(np.log(np.array(scores)) / np.log(10))\n",
    "plt.show()\n",
    "plt.title('Diversity')\n",
    "plt.plot(diversities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kw = {\n",
    "\"pipeline\": [\n",
    "    {\"name\": \"imagefilelist\", \"params\": {\"pattern\": \"{chairs}\"}},\n",
    "    {\"name\": \"shuffle\", \"params\": {}},\n",
    "    {\"name\": \"imageread\", \"params\": {}},\n",
    "    {\"name\": \"normalize_shape\", \"params\": {}},\n",
    "    {\"name\": \"force_rgb\", \"params\": {}},\n",
    "    {\"name\": \"crop\", \"params\": {\"shape\": (128, 128), \"pos\": \"center\", \"mode\": \"constant\"}},   \n",
    "    {\"name\": \"resize\", \"params\": {\"shape\": [h, w]}},\n",
    "    {\"name\": \"divide_by\", \"params\": {\"value\": 255}},\n",
    "    {\"name\": \"order\", \"params\": {\"order\": \"th\"}}\n",
    "]\n",
    "}\n",
    "dt_test = load_data('loader', w=w, h=h, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load from file\n",
    "c=3\n",
    "nb = 100\n",
    "dt = dt_test.X[0:nb]\n",
    "try:\n",
    "    dt = dt.reshape((nb, c, w, h))\n",
    "except Exception:\n",
    "    dt = dt.reshape((nb, c, w, h))\n",
    "    dt = dt * np.ones((1, 3, 1, 1))\n",
    "    dt = dt.astype(np.float32)\n",
    "print(dt.shape)\n",
    "rec = reconstruct(dt)\n",
    "print(((rec - dt)**2).mean())\n",
    "\n",
    "im1 = disp_grid(model.preprocess(dt[0:nb]), border=1, bordercolor=(.3, .3, .3))\n",
    "im2 = disp_grid(reconstruct(model.preprocess(rec[0:nb])), border=1, bordercolor=(.5, 0, 0))\n",
    "im_mix = np.empty((im1.shape[0], im1.shape[1] + im2.shape[1], 3))\n",
    "im_mix[:, 0:im1.shape[1]] = im1\n",
    "im_mix[:, im1.shape[1]:] = im2\n",
    "imsave('imgs/im_mix_new_dataset.png', im_mix)\n",
    "Image('imgs/im_mix_new_dataset.png', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lay = tuple(coord_layers)\n",
    "#lay = ('input',)\n",
    "tensors = tuple(T.TensorType('float32', (False,)* len(layers[l].output_shape) )() for l in lay)\n",
    "img2code = build_image_to_code_func(layers, lay=lay)\n",
    "code2img = build_code_to_image(layers, lay=lay, X=tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.random.randint(0, len(data.X), size=4)\n",
    "codes = img2code(model.preprocess(data.X[indices]))\n",
    "shapes = [c.shape[1:] for c in codes]\n",
    "codes_flat = [c.reshape(c.shape[0], -1) for c in codes]\n",
    "sizes = [c.shape[1] for c in codes_flat]\n",
    "codes_concat = np.concatenate(codes_flat, axis=1)\n",
    "\n",
    "z_dim = codes_concat.shape[1:]\n",
    "D = 30\n",
    "alpha = np.linspace(0, 1, D)\n",
    "beta = np.linspace(0, 1, D)\n",
    "grid_codes = np.empty((D*D,) + z_dim, dtype='float32')\n",
    "k = 0\n",
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        grid_codes[k] = a*b*codes_concat[0] + a*(1-b)*codes_concat[1] + (1-a)*b*codes_concat[2]  + (1-a)*(1-b)*codes_concat[3]\n",
    "        k +=1\n",
    "\n",
    "i = 0\n",
    "orig_codes = []\n",
    "for s in sizes:\n",
    "    orig_codes.append(grid_codes[:, i:i+s])\n",
    "    i+=s\n",
    "orig_codes = [orig_code.reshape((orig_code.shape[0],) + shape) for orig_code, shape in zip(orig_codes, shapes)]\n",
    "print(orig_codes[0].shape)\n",
    "grid_imgs = code2img(*orig_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imsave('imgs/grid.png', disp_grid(grid_imgs, border=2, bordercolor=(0.3,0.,0.)))\n",
    "Image('imgs/grid.png', width=500, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
