{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "os.environ['THEANO_FLAGS'] = 'device=gpu'\n",
    "sys.path.append(os.getcwd()+\"/..\")\n",
    "from tools.system.imgtovideo import imgs_to_video\n",
    "from data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers as L\n",
    "from lasagnekit.misc.plot_weights import dispims_color, tile_raster_images\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "import json\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "\n",
    "\n",
    "from tools.brushstroke.common import (\n",
    "    resize_set, load_model, get_bias, \n",
    "    get_scale, build_brush_func,\n",
    "    build_encode_func,\n",
    "    build_image_to_code_func,\n",
    "    build_code_to_image,\n",
    "    to_grid_of_images,\n",
    "    seq_to_video,\n",
    "    embed_video,\n",
    "    disp_grid,\n",
    "    prop_uniques,\n",
    "    hash_array,\n",
    "    normalize,\n",
    "    sigmoid,\n",
    "    build_pointer_images)\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def accumulate(X, fn):\n",
    "    for t in range(1, X.shape[1]):\n",
    "        X[:, t] = fn(X[:, t], X[:, t - 1])\n",
    "    return X\n",
    "\n",
    "def mask_op(new, prev, eps=0.1):\n",
    "    img1 = prev\n",
    "    img2 = new\n",
    "    a2 = 1 - (np.abs(img2[:,0])<eps) * (np.abs(img2[:,1])<eps) * (np.abs(img2[:,2])<eps)   \n",
    "    a2=a2[:,None, :, :]\n",
    "    img = img1 * (1 - a2) + img2 * a2\n",
    "    return img\n",
    "\n",
    "def smooth_mask_op(new, prev):\n",
    "    img1 = prev\n",
    "    img2 = new\n",
    "    a2 = new.mean(axis=1, keepdims=True)\n",
    "    img = img1 * (1 - a2) + img2 * a2\n",
    "    return img\n",
    "\n",
    "def softmax(x):\n",
    "    x = np.exp(x)\n",
    "    return x / x.sum(axis=1, keepdims=True)\n",
    "\n",
    "def sparse_softmax(x):\n",
    "    m = np.max(x, axis=1, keepdims=True)\n",
    "    return softmax(x) * (x==m)\n",
    "\n",
    "def softmax_t(x):\n",
    "    return softmax(x*100)\n",
    "\n",
    "from utils.sparsemax_theano import sparsemax as sparsemax_theano\n",
    "m = T.matrix()\n",
    "sparsemax = theano.function([m], sparsemax_theano(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and build functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, data, layers = load_model(\"../jobs/results/cc0d71a2ba9464e18f089f5bd554dce2/model.pkl\", \n",
    "                                 data_params={'nb_examples': 200, 'image_collection_mode': 'random'})\n",
    "w, h = layers['output'].output_shape[2:]\n",
    "print(json.dumps(model.hypers['model_params'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_parallel = model.hypers['model_params'].get('parallel', 1)\n",
    "coord_layers = [l for l in layers.keys() if 'coord' in l]\n",
    "brush_layers = [l for l in layers.keys() if 'brush' in l]\n",
    "coord = coord_layers[0]\n",
    "brush = brush_layers[0]\n",
    "X = T.tensor4()\n",
    "C = T.tensor3()    \n",
    "get_brushes = theano.function(\n",
    "    [X], \n",
    "    L.get_output(layers[brush], X))\n",
    "encoders = []\n",
    "for c in coord_layers:\n",
    "    encoder = build_encode_func(layers, lay=c)\n",
    "    encoders.append(encoder)\n",
    "get_reprs = []\n",
    "for c in coord_layers:\n",
    "    get_reprs.append(theano.function([X], L.get_output(layers[c], X)))\n",
    "get_repr = theano.function([X], L.get_output(layers[coord], X))\n",
    "get_brush = build_brush_func(\n",
    "    layers, \n",
    "    lay=brush_layers,\n",
    "    nonlin=lambda x:x) # transforms an image to sequence of imagess\n",
    "reconstruct = model.reconstruct # reconstructs an image\n",
    "\n",
    "if 'scaled_output' in layers:\n",
    "    scale = get_scale(layers)\n",
    "else:\n",
    "    scale = np.array([1])\n",
    "if 'biased_output' in layers:\n",
    "    bias = get_bias(layers)\n",
    "else:\n",
    "    bias = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_brush = build_brush_func(\n",
    "    layers, \n",
    "    lay=brush_layers,\n",
    "    nonlin=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2code = build_image_to_code_func(layers, lay=tuple(coord_layers))\n",
    "tensors = tuple([T.tensor3() for _ in range(len(coord_layers))])\n",
    "code2img = build_code_to_image(layers, X=tensors, lay=tuple(coord_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'biased_resid_output' in layers:\n",
    "    X = T.tensor4()\n",
    "    get_resid = theano.function([X], L.get_output(layers['biased_resid_output'], X))\n",
    "    get_out = theano.function([X], L.get_output(layers['biased_output'], X))\n",
    "    get_raw_out = theano.function([X], L.get_output(layers['raw_output'], X))\n",
    "    get_out_from_raw_out = theano.function([X], L.get_output(layers['output'], {layers['raw_output']:X}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.load()\n",
    "X = model.preprocess(data.X[0:10*10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x:'{:.4f}'.format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_colors = [\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 1 ,0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 1],\n",
    "    [0, 0, 0]\n",
    "]\n",
    "real_colors = np.array(real_colors, dtype='float32')\n",
    "\n",
    "img = real_colors[np.newaxis, np.newaxis, :, :] * np.ones((30, 30, 1, 3))\n",
    "print(img.shape)\n",
    "img = img.transpose((2, 3, 0, 1))\n",
    "img = disp_grid(img, normalize=False, border=1, bordercolor=(0.3,0,0))\n",
    "imsave('imgs/colors.png', img)\n",
    "Image('imgs/colors.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_steps = model.hypers['model_params']['n_steps']\n",
    "code = np.zeros((len(layers['brush'].colors_.get_value()), n_steps, layers['coord'].output_shape[2]  ))\n",
    "code = code.astype(np.float32)\n",
    "code[:, :, 0] = 0\n",
    "code[:, :, 1] = 0\n",
    "code[:, :, 3] = 1000\n",
    "code[:, :, 5] = 1000\n",
    "C = np.arange(len(code))\n",
    "code[C, :, C+6] = 100\n",
    "img = code2img(code)\n",
    "img = disp_grid(img, normalize=False, border=1, bordercolor=(0.3,0,0))\n",
    "img = np.clip(img, 0, 1)\n",
    "imsave('imgs/colors.png', img)\n",
    "Image('imgs/colors.png', width=200, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = (  (layers['brush'].colors_.get_value()) * scale.flatten() + bias.flatten())\n",
    "print(img.min(), img.max())\n",
    "img = np.clip(img, 0, 1)\n",
    "img = img[:, :, None, None] * np.ones((1, 3, 30, 30))\n",
    "img = disp_grid(img, normalize=False, border=1, bordercolor=(0.3, 0, 0))\n",
    "imsave('imgs/colors.png', img)\n",
    "Image('imgs/colors.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers['brush'].assign_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codes = img2code(X)\n",
    "r = codes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1 = softmax(r[:, 0, 6:14])\n",
    "r1/=r1.max(axis=1, keepdims=True)\n",
    "r2 = softmax(r[:, 1, 6:14])\n",
    "r2/=r2.max(axis=1, keepdims=True)\n",
    "zero = np.zeros((r1.shape[0], 10))\n",
    "s = np.hstack((r1, zero, r2))\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "plt.imshow(s, cmap='viridis', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codes = img2code(X)\n",
    "r = codes[0]\n",
    "pr = sparse_softmax(r[:, 0, 6:14])\n",
    "c = np.dot(pr, (layers['brush'].colors_.get_value())  )\n",
    "c = c * scale.flatten() + bias.flatten()\n",
    "c = c[:, :, np.newaxis, np.newaxis] * np.ones((1, 1, 16, 16))\n",
    "c = np.clip(c, 0, 1)\n",
    "imsave('imgs/b.png', \n",
    "       disp_grid(c, border=1, bordercolor=(0.3,0,0), normalize=False)\n",
    ")\n",
    "Image('imgs/b.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize, NoNorm\n",
    "b, = get_brush(X)\n",
    "b = (b* scale + bias)\n",
    "b = np.clip(b, 0, 1)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "imsave('imgs/b.png', \n",
    "       disp_grid(b[:, 1], border=1, bordercolor=(0.3,0,0), normalize=False)\n",
    ")\n",
    "Image('imgs/b.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codes = img2code(X)\n",
    "r = codes[0]\n",
    "img = code2img(*codes)\n",
    "img = np.clip(img, 0, 1)\n",
    "img = disp_grid(img, border=1, bordercolor=(0.3,0.3,0.3), normalize=False)\n",
    "imsave('imgs/im.png', img)\n",
    "Image('imgs/im.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a sequence with the enhancement module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def construct_seq(X):\n",
    "    seq = []\n",
    "    feat = img2code(X)\n",
    "    for t in range(layers[coord_layers[0]].output_shape[1]):\n",
    "        feat_ = [f.copy() for f in feat]\n",
    "        for f in feat_:\n",
    "            f[:,t+1:]=-100\n",
    "        img = code2img(*feat_)\n",
    "        seq.append(img)\n",
    "    return seq\n",
    "\n",
    "seq = construct_seq(X)\n",
    "seq = np.array(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_ = np.array(seq[:])\n",
    "seq_ = seq.transpose((1, 0, 2, 3, 4))\n",
    "seq_to_video(seq_, 'vids/refined_seq.mp4')\n",
    "embed_video('vids/refined_seq.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get coords from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codes = []\n",
    "for encoder in get_reprs:\n",
    "    code = encoder(X)\n",
    "    codes.append(code)\n",
    "cols = [(1, 0, 0), (0, 1, 0), (0, 0, 1), (1, 1, 0), (1, 0, 1), (0, 1, 1)]\n",
    "cols = cols + cols\n",
    "print(model.hypers['model_params']['patch_size'])\n",
    "pointers = []\n",
    "for i, code in enumerate(codes):\n",
    "    if 'x_stride' in layers['brush_0'].assign_:\n",
    "        print(code.shape)\n",
    "        sx = sigmoid(code[:,:, layers['brush_0'].assign_['x_stride']]) * model.hypers['model_params']['patch_size']\n",
    "    else:\n",
    "        sx = None    \n",
    "\n",
    "    if 'y_stride' in layers['brush_0'].assign_:\n",
    "        sy = sigmoid(code[:,:, layers['brush_0'].assign_['y_stride']]) * model.hypers['model_params']['patch_size']\n",
    "    else:\n",
    "        sy = None\n",
    "    pointer = build_pointer_images(code[:, :, 0:2], cols[i], w, h, sx=sx, sy=sy, p=1)\n",
    "    pointers.append(pointer)\n",
    "pointers = sum(pointers)\n",
    "seq_to_video(pointers, 'vids/pointers.mp4')\n",
    "embed_video('vids/pointers.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video of gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs = get_brush(X) # (examples, time, c, w, h)\n",
    "imgs = sum(imgs)\n",
    "imgs = imgs * scale + bias\n",
    "imgs = imgs\n",
    "imgs = np.clip(imgs, 0, 1)\n",
    "seq_to_video(imgs, 'vids/seq.mp4', border=2, bordercolor=(0.3,0,0),framerate=1, rate=1, normalize=False)\n",
    "embed_video('vids/seq.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,20))\n",
    "d = imgs[:,-1].copy()\n",
    "d = disp_grid(d)\n",
    "ax1.set_axis_off()\n",
    "ax1.imshow(d)\n",
    "m = get_resid(X)\n",
    "d = ( ((get_resid(X)+get_out(X)))*0.5     )\n",
    "#d = 1-sigmoid(d)\n",
    "d = normalize(d, axis=0)\n",
    "d = disp_grid(d)\n",
    "ax2.set_axis_off()\n",
    "ax2.imshow(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im1 = disp_grid(model.preprocess(data.X[0:100]), border=1, bordercolor=(.3, .3, .3))\n",
    "r  = model.reconstruct(model.preprocess(data.X[0:100]))\n",
    "r = np.clip(r, 0, 1)\n",
    "im2 = disp_grid(r, border=1, bordercolor=(.5, 0, 0), normalize=False)\n",
    "im_mix = np.empty(( max(im1.shape[0], im2.shape[0]), im1.shape[1] + im2.shape[1], 3))\n",
    "im_mix[0:im1.shape[0], 0:im1.shape[1]] = im1\n",
    "im_mix[0:im2.shape[0], im1.shape[1]:] = im2\n",
    "imsave('imgs/im_mix.png', im_mix)\n",
    "Image('imgs/im_mix.png', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.draw import circle\n",
    "texture = imread('imgs/metal_rust_texture_05_by_fantasystock.jpg')/255.\n",
    "plt.imshow(texture)\n",
    "S = 4\n",
    "x = 200\n",
    "patches = np.zeros((1, 3, 7*S, 7*S))\n",
    "ph, pw = patches.shape[2:]\n",
    "rr, cc = circle(ph/2, pw/2, S*3)    \n",
    "#patches[:, :, rr, cc] = 1\n",
    "#plt.imshow(patches[0,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.draw import circle\n",
    "\n",
    "r = get_repr(X)\n",
    "\n",
    "\n",
    "def sharpen_draw_single(gx, gy, patch, col, w_out, h_out, img=None, mask=None):\n",
    "    c = patch.shape[0]\n",
    "    ph = patch.shape[1]\n",
    "    pw = patch.shape[2]\n",
    "    if img is  None:\n",
    "        img = np.zeros((c, w_out, h_out))\n",
    "        mask = np.zeros((c, w_out, h_out))\n",
    "    shape = img[:, gy:gy+ph, gx:gx+pw].shape\n",
    "    \n",
    "    n = patch[:, :shape[1], :shape[2]] * col[:, None, None]\n",
    "    mask_n = (1 - (n[0]==0) * (n[1]==0) * (n[2]==0))\n",
    "    o =   img[:, gy:gy+ph, gx:gx+pw]\n",
    "    mask_o = (1 - (o[0]==0) * (o[1]==0) * (o[2]==0))\n",
    "    img[:, gy:gy+ph, gx:gx+pw] = n * mask_n + o * (1 - mask_n) \n",
    "    img[:, gy:gy+ph, gx:gx+pw] = n * 0.5 + o * 0.5 \n",
    "    \n",
    "    return img\n",
    "\n",
    "def sharpen_draw(r, S=8):\n",
    "    br = 'brush_0'\n",
    "    \n",
    "    if 'patch_index' in layers[br].assign_:\n",
    "        patch_indices = layers[br].assign_['patch_index']\n",
    "    else:\n",
    "        patch_indices = None\n",
    "    if 'color' in layers[br].assign_:\n",
    "        color_indices = layers[br].assign_['color']\n",
    "    else:\n",
    "        color_indices = None\n",
    "    patches = layers[br].patches_.get_value()\n",
    "    patches = np.ones((1, 3, S*7, S*7))\n",
    "    ph, pw = patches.shape[2:]    \n",
    "    ph, pw = patches.shape[2:]\n",
    "    rr, cc = circle(ph/2, pw/2, S*3)\n",
    "    #patches[:, :, rr, cc] = 1\n",
    "    #patches[:] *= texture.transpose((2, 0, 1))[:, 100:100+ph, 100:100+pw]\n",
    "    w_out = w * S\n",
    "    h_out = h * S\n",
    "    c = patches.shape[1]\n",
    "    imgs = np.zeros((r.shape[0], c, h_out, w_out))\n",
    "    masks = np.zeros_like(imgs)\n",
    "\n",
    "    for t in range(r.shape[1]):\n",
    "        rt = r[:, t]\n",
    "        if patch_indices:\n",
    "            patch_index = rt[:, slice(*patch_indices)].argmax(axis=1)\n",
    "        else:\n",
    "            patch_index = np.zeros((rt.shape[0],))\n",
    "        if color_indices:\n",
    "            color = (rt[:, slice(*color_indices)])\n",
    "            color = sigmoid(color)\n",
    "        else:\n",
    "            color = np.ones((rt.shape[0], layers['output'].output_shape[1]))\n",
    "        for i in range(imgs.shape[0]):\n",
    "            gx = int(sigmoid(rt[i, 0]) * w_out)\n",
    "            gy = int(sigmoid(rt[i, 1]) * h_out)\n",
    "            sharpen_draw_single(gx, gy, patches[patch_index[i]], color[i], w_out, h_out, img=imgs[i], mask=masks[i])\n",
    "    return imgs\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "imgs = sharpen_draw(r, S=2)\n",
    "imgs = imgs * scale[0] + bias[0]\n",
    "imgs = sigmoid(imgs)\n",
    "imgs = np.clip(imgs, 0, 1)\n",
    "\n",
    "#imgs = 1-sigmoid(imgs)\n",
    "img = disp_grid(imgs)\n",
    "imsave('imgs/sharpen.png', img)\n",
    "Image('imgs/sharpen.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterative refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.random.seed(22)\n",
    "nb_iter = 100\n",
    "nb_examples = 100\n",
    "thresh = None\n",
    "use_noise = True\n",
    "learning_rate = 1\n",
    "c = layers['output'].output_shape[1]\n",
    "# PREP\n",
    "if thresh == 'moving':\n",
    "    whitepx_ratio = (data.X>0.5).sum() / np.ones_like(data.X).sum()\n",
    "\n",
    "imgs = np.empty((nb_examples, nb_iter + 1, c, w, h)) # 1 = color channel\n",
    "imgs = imgs.astype(np.float32)\n",
    "imgs[:, 0] = np.random.uniform(size=(nb_examples, c, w, h))\n",
    "\n",
    "if use_noise: noise = np.random.normal(0, 0.001, size=imgs[:, 0].shape).astype(np.float32) #(for colored images)\n",
    "else: noise = 0\n",
    "\n",
    "scores = []\n",
    "diversities = []\n",
    "\n",
    "# ITERATIOn\n",
    "\n",
    "for i in tqdm(range(1, nb_iter + 1)):\n",
    "    \n",
    "    if use_noise:noise = np.random.normal(0, 1, size=imgs[:, 0].shape).astype(np.float32) #(for colored images)\n",
    "    else:noise = 0\n",
    "    \n",
    "    new = model.reconstruct(imgs[:, i - 1] + noise)\n",
    "    prev = imgs[:, i - 1] \n",
    "    imgs[:, i] = new * learning_rate + prev * (1-learning_rate)\n",
    "    if c == 1:\n",
    "        if thresh == 'moving':\n",
    "            vals = imgs[:, i].flatten()\n",
    "            vals = vals[np.argsort(vals)]\n",
    "            thresh_ = vals[-int(whitepx_ratio * len(vals)) - 1]\n",
    "        else:\n",
    "            thresh_ = thresh\n",
    "        if thresh_:\n",
    "            imgs[:, i] = imgs[:, i] > thresh_ # binarize\n",
    "    score = np.abs(imgs[:, i - 1] - imgs[:, i]).sum()\n",
    "    scores.append(score)\n",
    "    diversity = prop_uniques(imgs[:, i])\n",
    "    diversities.append(diversity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check nearest neighbors in dataset of the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d0dcfc23ee12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnb_neighb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#c=3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imgs' is not defined"
     ]
    }
   ],
   "source": [
    "nb_neighb = 20\n",
    "#c=3\n",
    "generated = imgs[0:20, -1].copy()\n",
    "generated = np.clip(generated, 0, 1)\n",
    "dataset = model.preprocess(data.X)\n",
    "def euc(x, y):\n",
    "    return ((x-y)**2).mean(axis=(2, 3, 4))\n",
    "dist = euc\n",
    "\n",
    "neighb = (dist(generated[:, None], dataset[None, :])).argsort(axis=1)\n",
    "neighb = neighb[:, 0:nb_neighb]\n",
    "shape = neighb.shape\n",
    "neighb = neighb.flatten()\n",
    "neighb = dataset[neighb]\n",
    "neighb = neighb.reshape((shape[0], shape[1], c, h, w))\n",
    "neighb = np.concatenate((generated[:, None], neighb), axis=1)\n",
    "img = np.empty(( shape[0]*h, shape[1] *w, c))\n",
    "for y in range(shape[0]):\n",
    "    for x in range(shape[1]):\n",
    "        img[y*h:y*h+h, x*w:x*w+w] = neighb[y,x].transpose((1, 2, 0))\n",
    "        \n",
    "        img[y*h:y*h+h, x*w:x*w+1]=0.3 if x>1 else 1\n",
    "        img[y*h:y*h+1, x*w:x*w+w+1]=0.3 if x>0 else 1\n",
    "         \n",
    "imsave('imgs/neigh.png', img[:,:,0] if c==1 else img)\n",
    "Image('imgs/neigh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5b0c72561af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mim_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "im = imgs[:, -1]\n",
    "im = np.clip(im, 0, 1)\n",
    "p = 5\n",
    "im_pad = np.zeros((im.shape[0], im.shape[1], im.shape[2]+2*p, im.shape[3]+2*p))\n",
    "for i in range(im.shape[0]):\n",
    "    for j in range(c):\n",
    "        im_pad[i, j] = np.pad(im[i, j], (p, p), 'constant', constant_values=1)\n",
    "im = im_pad\n",
    "img = disp_grid(im, border=1, bordercolor=(0.3, 0, 0), normalize=False)\n",
    "imsave('imgs/ir.png', img)\n",
    "Image('imgs/ir.png', width=500, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq_to_video(np.clip(imgs, 0, 1), 'vids/ir.mp4', border=2, bordercolor=(0.3, 0, 0), normalize=False)\n",
    "embed_video('vids/ir.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Score')\n",
    "plt.plot(np.log(np.array(scores)) / np.log(10))\n",
    "plt.show()\n",
    "plt.title('Diversity')\n",
    "plt.plot(diversities)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kw = {\n",
    "\"pipeline\": [\n",
    "    {\"name\": \"imagefilelist\", \"params\": {\"pattern\": \"{chairs}\"}},\n",
    "    {\"name\": \"shuffle\", \"params\": {}},\n",
    "    {\"name\": \"imageread\", \"params\": {}},\n",
    "    {\"name\": \"normalize_shape\", \"params\": {}},\n",
    "    {\"name\": \"force_rgb\", \"params\": {}},\n",
    "    {\"name\": \"crop\", \"params\": {\"shape\": (128, 128), \"pos\": \"center\", \"mode\": \"constant\"}},   \n",
    "    {\"name\": \"resize\", \"params\": {\"shape\": [h, w]}},\n",
    "    {\"name\": \"divide_by\", \"params\": {\"value\": 255}},\n",
    "    {\"name\": \"order\", \"params\": {\"order\": \"th\"}}\n",
    "]\n",
    "}\n",
    "dt_test = load_data('loader', w=w, h=h, **kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load from file\n",
    "c=3\n",
    "nb = 100\n",
    "dt = dt_test.X[0:nb]\n",
    "try:\n",
    "    dt = dt.reshape((nb, c, w, h))\n",
    "except Exception:\n",
    "    dt = dt.reshape((nb, c, w, h))\n",
    "    dt = dt * np.ones((1, 3, 1, 1))\n",
    "    dt = dt.astype(np.float32)\n",
    "print(dt.shape)\n",
    "rec = reconstruct(dt)\n",
    "print(((rec - dt)**2).mean())\n",
    "\n",
    "im1 = disp_grid(model.preprocess(dt[0:nb]), border=1, bordercolor=(.3, .3, .3), normalize=False)\n",
    "im2 = disp_grid(np.clip(reconstruct(model.preprocess(rec[0:nb])), 0, 1), \n",
    "                border=1, bordercolor=(.5, 0, 0), normalize=False)\n",
    "im_mix = np.empty((im1.shape[0], im1.shape[1] + im2.shape[1], 3))\n",
    "im_mix[:, 0:im1.shape[1]] = im1\n",
    "im_mix[:, im1.shape[1]:] = im2\n",
    "imsave('imgs/im_mix_new_dataset.png', im_mix)\n",
    "Image('imgs/im_mix_new_dataset.png', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lay = tuple(coord_layers)\n",
    "#lay = ('input',)\n",
    "tensors = tuple(T.TensorType('float32', (False,)* len(layers[l].output_shape) )() for l in lay)\n",
    "img2code = build_image_to_code_func(layers, lay=lay)\n",
    "code2img = build_code_to_image(layers, lay=lay, X=tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, len(data.X), size=4)\n",
    "codes = img2code(model.preprocess(data.X[indices]))\n",
    "shapes = [c.shape[1:] for c in codes]\n",
    "codes_flat = [c.reshape(c.shape[0], -1) for c in codes]\n",
    "sizes = [c.shape[1] for c in codes_flat]\n",
    "codes_concat = np.concatenate(codes_flat, axis=1)\n",
    "\n",
    "z_dim = codes_concat.shape[1:]\n",
    "D = 30\n",
    "alpha = np.linspace(0, 1, D)\n",
    "beta = np.linspace(0, 1, D)\n",
    "grid_codes = np.empty((D*D,) + z_dim, dtype='float32')\n",
    "k = 0\n",
    "for a in alpha:\n",
    "    for b in beta:\n",
    "        grid_codes[k] = a*b*codes_concat[0] + a*(1-b)*codes_concat[1] + (1-a)*b*codes_concat[2]  + (1-a)*(1-b)*codes_concat[3]\n",
    "        k +=1\n",
    "\n",
    "i = 0\n",
    "orig_codes = []\n",
    "for s in sizes:\n",
    "    orig_codes.append(grid_codes[:, i:i+s])\n",
    "    i+=s\n",
    "orig_codes = [orig_code.reshape((orig_code.shape[0],) + shape) for orig_code, shape in zip(orig_codes, shapes)]\n",
    "print(orig_codes[0].shape)\n",
    "grid_imgs = code2img(*orig_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imsave('imgs/grid.png', disp_grid(grid_imgs, border=2, bordercolor=(0.3,0.,0.)), normalize=False)\n",
    "Image('imgs/grid.png', width=500, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
