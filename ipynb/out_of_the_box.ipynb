{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K20Xm (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005)\n",
      "/home/mcherti/work/code/external/scikit-learn/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=gpu,compiledir=.gpu'\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.common import disp_grid\n",
    "from IPython.display import Image\n",
    "from skimage.io import imsave\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from lightjob.cli import load_db\n",
    "#from skimage.io import imread\n",
    "from tools.common import find_generation_job, find_training_job, to_generation, compute_sample_objectness, resize_set\n",
    "from IPython.display import Image, display\n",
    "from lightjob.cli import load_db\n",
    "from lightjob.db import SUCCESS\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from joblib.parallel import delayed, Parallel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def disp_pred(pred, h=20, w=100, y0=25, fontsize=0.9):\n",
    "    nb_classes = len(pred)\n",
    "    img = np.zeros((nb_classes * h, w, 3))\n",
    "    cv2.rectangle(img,(0,0),(img.shape[1],img.shape[0]),(0.3,0.3,0.3),3)\n",
    "    pad = 0\n",
    "    col = [[0, 0, 1]] * nb_classes\n",
    "    for i in range(nb_classes):\n",
    "        p = int(w * pred[i])\n",
    "        img[i*(h+pad):i*(h+pad)+h, 0:p, :] = col[i]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in range(nb_classes):\n",
    "        cv2.putText(img,str(i),(10,y0+h*i), font, fontsize,(1,1,1),1,cv2.LINE_AA)\n",
    "        cv2.rectangle(img,(0, i*(h+pad)),(w, i*(h+pad)+h),(0.3,0.3,0.3),2)\n",
    "\n",
    "    return img\n",
    "\n",
    "def disp_grid_with_pred(img, preds, h=30, w=200, y0=25, fontsize=0.9):\n",
    "    img = resize_set(img, 100, 100)\n",
    "    img_ = np.zeros((img.shape[0], 3, img.shape[2]*2, img.shape[3]*2))\n",
    "    img_[:, :, 0:img.shape[2], 0:img.shape[3]] = img[:, :, :, :]\n",
    "    for i, pr in enumerate(preds):\n",
    "        text= disp_pred(pr, h=h, w=w, y0=y0, fontsize=fontsize)\n",
    "        text = resize(text, (img.shape[2], img.shape[3]))\n",
    "        text = text.transpose((2, 0, 1))\n",
    "        img_[i, :, 0:img.shape[2], img.shape[3]:] = text\n",
    "    img_ = disp_grid(img_)\n",
    "    return img_\n",
    "\n",
    "from tools.common import resize_set\n",
    "import shutil\n",
    "from tools.common import compute_objectness, compute_objectness_renyi, compute_sample_objectness, compute_sample_objectness_renyi\n",
    "def load_h5(filename):\n",
    "    f = h5py.File(filename)\n",
    "    X = f['X']\n",
    "    nb = f.attrs['nb']\n",
    "    X = X[0:nb]\n",
    "    X = np.array(X)\n",
    "    X = X[np.isnan(X).sum(axis=(1,2,3))==0]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_folder = '../tools/models/external/fonts'\n",
    "arch = (open(os.path.join(model_folder, 'model.json'))).read()\n",
    "model = model_from_json(arch)\n",
    "model.load_weights(os.path.join(model_folder, 'model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking all generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = joblib.load('../../external/dcgan_code/mnist/models/uncond_dcgan/200_gen.npz') # gan\n",
    "X = load_h5('../exported_data/datasets/jobset83.hdf5')\n",
    "#X = load_h5('../exported_data/datasets/jobset76.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 2048\n",
    "preds = []\n",
    "for i in range(0, len(X), batch_size):\n",
    "    x = X[i:i+batch_size]\n",
    "    preds.append(model.predict(x))\n",
    "preds = np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dt = np.load('/home/mcherti/work/data/hwrt/data_50classes.npz')\n",
    "#m = {a: b for a, b in zip(dt['y'], dt['y_str'])}\n",
    "#for cl in m:\n",
    "#    print(cl, m[cl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n = 'abcdefghijklmnopqrstuvwxyz'.index('c')\n",
    "n = 0\n",
    "indices = np.arange(len(X))\n",
    "#indices = indices[compute_objectness(preds)>0.1]\n",
    "p=preds[:, n]\n",
    "indices = indices[np.argsort(p[indices])[::-1]]\n",
    "#indices = indices[p[indices]>0.5]\n",
    "img = X[indices]\n",
    "img = disp_grid(img[0:16], border=1, bordercolor=(0.3, 0, 0))\n",
    "imsave('imgs/out.png', img)\n",
    "Image('imgs/out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_classes = 26\n",
    "nbrows = 9\n",
    "nbcols = 3\n",
    "border = 1\n",
    "space = 10\n",
    "s = (28+border) * 4 + border\n",
    "img_all = np.zeros((nbrows * (s+space), nbcols * (s+space)  ))\n",
    "for i in range(nbrows):\n",
    "    for j in range(nbcols):\n",
    "        if i*nbcols+j>=nb_classes:\n",
    "            break\n",
    "        p=preds[:, i*nbcols+j]        \n",
    "        indices = indices[np.argsort(p[indices])[::-1]]\n",
    "        #indices = indices[p[indices]>0.5]\n",
    "        img = X[indices]\n",
    "        img = disp_grid(img[0:16], border=border, bordercolor=(0.3, 0, 0), shape=(4,4))\n",
    "        img_all[i*(s+space):i*(s+space) + s, j*(s+space):j*(s+space) + s] = img[:,:,0]\n",
    "imsave('imgs/all.png', img_all)\n",
    "Image('imgs/all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_real=preds_real[:, 5]\n",
    "real = Xreal[yreal==5][np.argsort(p_real[yreal == 5])[::-1][0:100]]\n",
    "fake = X[np.argsort(p)[::-1]][0:100]\n",
    "\n",
    "points_real = real.reshape((real.shape[0], -1))\n",
    "points_fake = fake.reshape((fake.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = NearestNeighbors(n_neighbors=30)\n",
    "nn.fit(points_real)\n",
    "dist, indices = nn.kneighbors(points_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighb = indices[:]\n",
    "print(indices.shape)\n",
    "h=28\n",
    "w=28\n",
    "c=1\n",
    "img = np.zeros((h*indices.shape[0], w*indices.shape[1]))\n",
    "for y in range(indices.shape[0]):\n",
    "    for x in range(indices.shape[1]):\n",
    "        img[y*h:y*h+h, x*w:x*w+w] = fake[y] if x== 0 else real[indices[y, x-1]]\n",
    "        img[y*h:y*h+h, x*w:x*w+1]=0.3 if x>1 else 1\n",
    "        img[y*h:y*h+1, x*w:x*w+w+1]=0.3 if x>0 else 1\n",
    "imsave('imgs/neigh.png', img)\n",
    "Image('imgs/neigh.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking stats of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = load_db()\n",
    "jobs = db.jobs_with(state=SUCCESS, where='jobset83')\n",
    "S = [j['summary'] for j in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_gen = to_generation(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field = 'stats.out_of_the_box_classification.m2.objectness'\n",
    "indices = np.arange(len(jobs))\n",
    "for i in range(len(jobs_gen)):\n",
    "    j = jobs_gen[i]\n",
    "    v = db.get_value(j, field, if_not_found=None)\n",
    "    #if not v:print('Misssing generation jobs from training job : {}, skip it.'.format(jobs[i]['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.arange(len(jobs))\n",
    "objectness = map(lambda j:db.get_value(j, field, if_not_found=np.nan), jobs_gen)\n",
    "objectness = np.array(objectness)\n",
    "indices = filter(lambda ind:not np.isnan(objectness[ind]), indices)\n",
    "indices = sorted(indices, key=lambda i:objectness[i])\n",
    "indices = indices[::-1]\n",
    "images = ['../exported_data/figs/generated/jobset{:05d}/{}.png'.format(int(jobs[i]['where'][6:]), jobs_gen[i]['summary']) \n",
    "          for i in indices]\n",
    "for i in range(len(images)):\n",
    "    #print(jobs_gen[indices[i]]['summary'])\n",
    "    shutil.copy(images[i], 'export/{:05d}.png'.format(i))\n",
    "    #if i<20:\n",
    "    #    display(Image(images[i], width=600, height=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## objectness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objectness = compute_sample_objectness_renyi(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = np.argsort(objectness)[::-1]\n",
    "X_sorted = X[ind]\n",
    "preds_sorted = preds[ind]\n",
    "objectness_sorted = objectness[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = np.arange(len(X))\n",
    "np.random.shuffle(sample)\n",
    "sample = sample[0:100]\n",
    "objectness_sampled = objectness[sample]\n",
    "X_sampled = X[sample]\n",
    "preds_sampled = preds[sample]\n",
    "X_sampled = X_sampled[np.argsort(objectness_sampled)[::-1]]\n",
    "preds_sampled = preds_sampled[np.argsort(objectness_sampled)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = disp_grid_with_pred(X_sorted[0::1000], preds_sorted[0::1000], h=200)\n",
    "imsave('imgs/out.png', im)\n",
    "Image('imgs/out.png', width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
