{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcherti/work/code/external/scikit-learn/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,compiledir_format=\"cpu\"'\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.common import disp_grid\n",
    "from IPython.display import Image\n",
    "from skimage.io import imsave\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from lightjob.cli import load_db\n",
    "#from skimage.io import imread\n",
    "from tools.common import find_generation_job, find_training_job, to_generation, compute_sample_objectness, resize_set\n",
    "from IPython.display import Image, display\n",
    "from lightjob.cli import load_db\n",
    "from lightjob.db import SUCCESS\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from joblib.parallel import delayed, Parallel\n",
    "\n",
    "\n",
    "def disp_pred(pred, h=20, w=100, y0=25):\n",
    "    nb_classes = len(pred)\n",
    "    img = np.zeros((nb_classes * h, w, 3))\n",
    "    cv2.rectangle(img,(0,0),(img.shape[1],img.shape[0]),(0.3,0.3,0.3),3)\n",
    "    pad = 0\n",
    "    col = [[0, 0, 1]] * nb_classes\n",
    "    for i in range(nb_classes):\n",
    "        p = int(w * pred[i])\n",
    "        img[i*(h+pad):i*(h+pad)+h, 0:p, :] = col[i]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in range(nb_classes):\n",
    "        cv2.putText(img,str(i),(10,y0+h*i), font, 0.9,(1,1,1),1,cv2.LINE_AA)\n",
    "        cv2.rectangle(img,(0, i*(h+pad)),(w, i*(h+pad)+h),(0.3,0.3,0.3),2)\n",
    "\n",
    "    return img\n",
    "\n",
    "def disp_grid_with_pred(img, preds):\n",
    "    img = resize_set(img, 100, 100)\n",
    "    img_ = np.zeros((img.shape[0], 3, img.shape[2]*2, img.shape[3]*2))\n",
    "    img_[:, :, 0:img.shape[2], 0:img.shape[3]] = img[:, :, :, :]\n",
    "    for i, pr in enumerate(preds):\n",
    "        text= disp_pred(pr, h=30, w=200)\n",
    "        text = resize(text, (img.shape[2], img.shape[3]))\n",
    "        text = text.transpose((2, 0, 1))\n",
    "        img_[i, :, 0:img.shape[2], img.shape[3]:] = text\n",
    "    img_ = disp_grid(img_)\n",
    "    return img_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = load_db()\n",
    "jobs = db.jobs_with(state=SUCCESS, where='jobset83')\n",
    "S = [j['summary'] for j in jobs]\n",
    "stats = {s: pd.read_csv('../jobs/results/{}/csv/stats.csv'.format(s)) for s in S}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_gen = to_generation(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_folder = '../tools/models/external/mnist_classifier'\n",
    "arch = (open(os.path.join(model_folder, 'model.json'))).read()\n",
    "model = model_from_json(arch)\n",
    "model.load_weights(os.path.join(model_folder, 'model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking all generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    from datakit.mnist import load\n",
    "    data = load(which='train')\n",
    "    X, y = data['train']['X'], data['train']['y']\n",
    "    X =  X / 255.\n",
    "    nb_classes = 10\n",
    "    X = X[:, None, :, :]\n",
    "    #X = X[y!=5]\n",
    "    #y = y[y!=5]\n",
    "    return X, y, nb_classes\n",
    "Xreal, yreal, _ = load_data()\n",
    "X = Xreal[yreal!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = joblib.load('../../external/dcgan_code/mnist/models/uncond_dcgan/10_gen.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = np.load('../exported_data/datasets/12457_vs_fake_jobset76.npz')\n",
    "y = d['y']\n",
    "data = d['X']\n",
    "data = data[:] # test data\n",
    "y = y[:] # test data\n",
    "data = data / 255.\n",
    "X = data[y==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "preds = []\n",
    "for i in range(0, len(X), batch_size):\n",
    "    preds.append(model.predict(X[i:i+batch_size]))\n",
    "preds = np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[400,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### CLASS = 1\n",
    "p=preds[:, 5]\n",
    "print(p.min(), p.max(),preds.shape)\n",
    "img = X[np.argsort(p)[::-1]]\n",
    "#print(y[np.argsort(p)][::-1])\n",
    "#img = img[ (p[np.argsort(p)[::-1]])>0.5 ]\n",
    "img = disp_grid(img[0:400], border=1, bordercolor=(0.3, 0, 0))\n",
    "imsave('imgs/out.png', img)\n",
    "Image('imgs/out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imsave('imgs/out.png', disp_grid(X[0:1000]))\n",
    "Image('imgs/out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real = Xreal[yreal!=5]\n",
    "points_real = real.reshape((real.shape[0], -1))\n",
    "print(points_real.shape)\n",
    "\n",
    "fake = X[np.argsort(p)[::-1]][0:100]\n",
    "is_real = np.array([1] * len(real) + [0] * len(fake))\n",
    "\n",
    "\n",
    "points = Xreal[yreal==5]\n",
    "points = points.reshape((points.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=30)\n",
    "nn.fit(points)\n",
    "dist, indices = nn.kneighbors(points_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for y in range(shape[0]):\n",
    "    for x in range(shape[1]):\n",
    "        img[y*h:y*h+h, x*w:x*w+w] = neighb[y,x].transpose((1, 2, 0))\n",
    "        img[y*h:y*h+h, x*w:x*w+1]=0.3 if x>1 else 1\n",
    "        img[y*h:y*h+1, x*w:x*w+w+1]=0.3 if x>0 else 1\n",
    "imsave('imgs/neigh.png', img[:,:,0] if c==1 else img)\n",
    "Image('imgs/neigh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample():\n",
    "    rng = np.random\n",
    "    pt = dict(\n",
    "        n_components=2,\n",
    "        perplexity=rng.choice((2, 5, 10, 30, 50, 100)),\n",
    "        early_exaggeration=rng.randint(1, 10),\n",
    "        learning_rate=rng.randint(100, 1000), \n",
    "        n_iter=5000,\n",
    "        n_iter_without_progress=500, \n",
    "        min_grad_norm=0, \n",
    "        metric='euclidean', \n",
    "        init=rng.choice(('pca', 'random')),\n",
    "        verbose=0, \n",
    "        random_state=None,\n",
    "        method='barnes_hut', \n",
    "        angle=0.5\n",
    "    )\n",
    "    return pt\n",
    "\n",
    "def run(pt):\n",
    "    points_ = points.reshape((points.shape[0], -1))\n",
    "    return TSNE(**pt).fit(points_)\n",
    "\n",
    "jobs = [sample() for _ in range(100)]\n",
    "models = Parallel(n_jobs=10, verbose=1)(delayed(run)(j) for j in jobs)\n",
    "kl = map(lambda m:m.kl_divergence_, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "perplexities = defaultdict(list)\n",
    "for m in models:\n",
    "    perplexities[m.perplexity].append(m)\n",
    "fig, ax = plt.subplots(1, len(perplexities), figsize=(25, 5))\n",
    "i = 0\n",
    "for perp in sorted(perplexities.keys()):\n",
    "    tsne = min(perplexities.get(perp), key=lambda model:model.kl_divergence_)\n",
    "    embedding = tsne.embedding_\n",
    "    ax[i].scatter(embedding[:, 0], embedding[:, 1])\n",
    "    ax[i].set_title('perplexity {}'.format(perp))\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsne = min(perplexities[10], key=lambda m:m.kl_divergence_)\n",
    "embedding = tsne.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tools.viz.image_scatter import image_scatter\n",
    "pts = points.reshape((points.shape[0], 28, 28)).copy()\n",
    "pts = pts[:, :, :, None] * np.ones((1, 1, 1, 3))\n",
    "pts[0:10, :, :, 1:]=0\n",
    "img = image_scatter(embedding, pts, 20, 500)\n",
    "imsave('imgs/out.png', img)\n",
    "Image('imgs/out.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking stats of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = load_db()\n",
    "jobs = db.jobs_with(state=SUCCESS, where='jobset83')\n",
    "S = [j['summary'] for j in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs_gen = to_generation(jobs, db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field = 'stats.out_of_the_box_classification.m2.objectness'\n",
    "indices = np.arange(len(jobs))\n",
    "for i in range(len(jobs_gen)):\n",
    "    j = jobs_gen[i]\n",
    "    v = db.get_value(j, field, if_not_found=None)\n",
    "    if not v:print('Misssing generation jobs from training job : {}, skip it.'.format(jobs[i]['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute(j):\n",
    "    if not j:return np.nan\n",
    "    data = joblib.load(\"../jobs/results/{}/images.npz\".format(j['summary']))\n",
    "    data = data[:, -1]\n",
    "    y = model.predict(data)\n",
    "    score = compute_objectness(y)\n",
    "    print(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "indices = np.arange(len(jobs))\n",
    "#objectness = map(lambda j:db.get_value(j, field, if_not_found=np.nan), jobs_gen)\n",
    "objectness = map(compute, jobs_gen)\n",
    "objectness = np.array(objectness)\n",
    "indices = filter(lambda ind:not np.isnan(objectness[ind]), indices)\n",
    "indices = sorted(indices, key=lambda i:objectness[i])\n",
    "indices = indices[::-1]\n",
    "images = ['../exported_data/figs/generated/jobset{:05d}/{}.png'.format(int(jobs[i]['where'][6:]), jobs_gen[i]['summary']) \n",
    "          for i in indices]\n",
    "print(jobs_gen[indices[1]]['summary'])\n",
    "for i in range(len(images)):\n",
    "    print(jobs_gen[indices[i]]['summary'])\n",
    "    shutil.copy(images[i], 'export/{:05d}.png'.format(i))\n",
    "    #display(Image(images[i]), width=100, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## objectness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_folder = '../tools/models/mnist/m2'\n",
    "#model_folder = '../../nnbench/out/feature_generation/12457_vs_fake_jobset76/'\n",
    "#model_folder = '../tools/models/mnist/m2'\n",
    "arch = (open(os.path.join(model_folder, 'model.json'))).read()\n",
    "#arch = arch.replace('softmax', 'linear')\n",
    "model = model_from_json(arch)\n",
    "model.load_weights(os.path.join(model_folder, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hf = h5py.File('../exported_data/datasets/jobset83.hdf5')\n",
    "X = hf['X']\n",
    "nb = hf.attrs['nb']\n",
    "X = X[0:nb]\n",
    "X[np.isnan(X)] = 0\n",
    "X = X[X.sum(axis=(1, 2, 3)) > 0]\n",
    "\n",
    "\"\"\"\n",
    "data = joblib.load('../jobs/results/1e47d7dea091c42c90b71ec06dee4f4d/images.npz')\n",
    "X = data[:, -1]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from datakit.mnist import load\n",
    "data = load(which='test')\n",
    "X = data['test']['X']\n",
    "y = data['test']['y']\n",
    "X = X / 255.\n",
    "X=X[0:1000]\n",
    "print(X.min(), X.max())\n",
    "print(X.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tools.common import compute_objectness\n",
    "\n",
    "def compute_objectness_renyi(v, alpha=2):\n",
    "    v = np.array(v)\n",
    "    marginal = v.mean(axis=0)\n",
    "    score = (1/(alpha-1)) * np.log(((v ** alpha) / marginal ** (alpha - 1)).sum(axis=1))\n",
    "    score = score.mean()\n",
    "    score = np.exp(score)\n",
    "    score = float(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "def compute_sample_objectness_renyi(v, alpha=2):\n",
    "    score = (1/(alpha-1)) * np.log((v**alpha).sum(axis=1))\n",
    "    return score\n",
    "\n",
    "preds = model.predict(X)\n",
    "#preds = (preds - preds.min(axis=0, keepdims=True)) / (preds.max(axis=0, keepdims=True) - preds.min(axis=0, keepdims=True))\n",
    "#objectness = compute_sample_objectness(preds)\n",
    "objectness = compute_sample_objectness_renyi(preds,alpha=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = np.argsort(objectness)[::-1]\n",
    "#ind =ordering\n",
    "X_sorted = X[ind]\n",
    "preds_sorted = preds[ind]\n",
    "objectness_sorted = objectness[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = np.arange(len(X))\n",
    "np.random.shuffle(sample)\n",
    "sample = sample[0:100]\n",
    "objectness_sampled = objectness[sample]\n",
    "X_sampled = X[sample]\n",
    "preds_sampled = preds[sample]\n",
    "X_sampled = X_sampled[np.argsort(objectness_sampled)[::-1]]\n",
    "preds_sampled = preds_sampled[np.argsort(objectness_sampled)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = disp_grid_with_pred(X_sorted[0::1000], preds_sorted[0::1000])\n",
    "imsave('imgs/out.png', im)\n",
    "Image('imgs/out.png', width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
