{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['THEANO_FLAGS'] = 'device=cpu,compiledir=.cpu'\n",
    "#os.environ['THEANO_FLAGS'] = 'device=cpu,compiledir=.cpu'\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.common import disp_grid\n",
    "from tools.common import preprocess_gen_data\n",
    "from IPython.display import Image\n",
    "from skimage.io import imsave\n",
    "from tools.common import load_model\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from lightjob.cli import load_db\n",
    "#from skimage.io import imread\n",
    "from tools.common import find_generation_job, find_training_job, to_generation, compute_sample_objectness, resize_set\n",
    "from IPython.display import Image, display\n",
    "from lightjob.cli import load_db\n",
    "from lightjob.db import SUCCESS\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from joblib.parallel import delayed, Parallel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def disp_pred(pred, h=20, w=100, y0=25, fontsize=0.9):\n",
    "    nb_classes = len(pred)\n",
    "    img = np.zeros((nb_classes * h, w, 3))\n",
    "    cv2.rectangle(img,(0,0),(img.shape[1],img.shape[0]),(0.3,0.3,0.3),3)\n",
    "    pad = 0\n",
    "    col = [[0, 0, 1]] * nb_classes\n",
    "    for i in range(nb_classes):\n",
    "        p = int(w * pred[i])\n",
    "        img[i*(h+pad):i*(h+pad)+h, 0:p, :] = col[i]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in range(nb_classes):\n",
    "        cv2.putText(img,str(i),(10,y0+h*i), font, fontsize,(1,1,1),1,cv2.LINE_AA)\n",
    "        cv2.rectangle(img,(0, i*(h+pad)),(w, i*(h+pad)+h),(0.3,0.3,0.3),2)\n",
    "\n",
    "    return img\n",
    "\n",
    "def disp_grid_with_pred(img, preds, h=30, w=200, y0=25, fontsize=0.9):\n",
    "    img = resize_set(img, 100, 100)\n",
    "    img_ = np.zeros((img.shape[0], 3, img.shape[2]*2, img.shape[3]*2))\n",
    "    img_[:, :, 0:img.shape[2], 0:img.shape[3]] = img[:, :, :, :]\n",
    "    for i, pr in enumerate(preds):\n",
    "        text= disp_pred(pr, h=h, w=w, y0=y0, fontsize=fontsize)\n",
    "        text = resize(text, (img.shape[2], img.shape[3]))\n",
    "        text = text.transpose((2, 0, 1))\n",
    "        img_[i, :, 0:img.shape[2], img.shape[3]:] = text\n",
    "    img_ = disp_grid(img_)\n",
    "    return img_\n",
    "\n",
    "from tools.common import resize_set\n",
    "import shutil\n",
    "from tools.common import compute_objectness, compute_objectness_renyi, compute_sample_objectness, compute_sample_objectness_renyi\n",
    "def load_h5(filename):\n",
    "    f = h5py.File(filename)\n",
    "    X = f['X']\n",
    "    nb = f.attrs['nb']\n",
    "    X = X[0:nb]\n",
    "    X = np.array(X)\n",
    "    X = X[np.isnan(X).sum(axis=(1,2,3))==0]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_folder = '../tools/models/external/fonts_and_digits'\n",
    "arch = (open(os.path.join(model_folder, 'model.json'))).read()\n",
    "#arch = arch.replace('softmax', 'linear')\n",
    "model = model_from_json(arch)\n",
    "model.load_weights(os.path.join(model_folder, 'model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking all generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = load_h5('../exported_data/datasets/jobset83.hdf5')\n",
    "#X = load_h5('../exported_data/datasets/jobset76.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = ['aa', 'gan']\n",
    "load_data = [\n",
    "    #lambda:load_h5('../exported_data/datasets/jobset83.hdf5')[500000:1000000],\n",
    "    lambda:joblib.load('../jobs/results/517302ec5da070804fd729e9bd44fdc8/images.npz')[:,-1],\n",
    "    lambda:joblib.load('/home/mcherti/dcgan/jobs/5a91ac06f1c52a41c2d43cb6423404d5/gen.npz')[0:1000]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preds_per_dataset = {}\n",
    "datasets = {}\n",
    "for name, d in zip(names, load_data):\n",
    "    X = d()\n",
    "    datasets[name] = X\n",
    "    batch_size = 2048\n",
    "    preds = []\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        x = X[i:i+batch_size]\n",
    "        preds.append(model.predict(x))\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    preds_per_dataset[name] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(preds_per_dataset['gan'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "classes = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def get_df(p, name):\n",
    "    df = pd.DataFrame()\n",
    "    df['argmax'] = map(lambda k:classes[k], p.argmax(axis=1))\n",
    "    df['argmax_count'] = [1./len(p)] * len(p)\n",
    "    df['model'] = [name] * len(p)\n",
    "    return df\n",
    "\n",
    "df_aa = get_df(preds_per_dataset['aa'], 'aa')\n",
    "df_gan = get_df(preds_per_dataset['gan'], 'gan')\n",
    "#df = pd.concat((df_aa, df_gan))\n",
    "df = df_aa\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = sns.barplot(x=\"argmax\", y=\"argmax_count\", hue='model', data=df, estimator=lambda x:x.sum(), order=classes)\n",
    "plt.xlabel('class')\n",
    "plt.ylabel('freq')\n",
    "plt.axvline(x=9.5, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n = 'abcdefghijklmnopqrstuvwxyz'.index('c')\n",
    "n = 3\n",
    "indices = np.arange(len(datasets['aa']))\n",
    "#indices = indices[compute_objectness(preds)>0.1]\n",
    "p=preds_per_dataset['aa'][:, n]\n",
    "indices = indices[np.argsort(p[indices])[::-1]]\n",
    "#indices = indices[p[indices]>0.5]\n",
    "img = datasets['aa'][indices]\n",
    "img = disp_grid(img[0:4], border=1, bordercolor=(0.3, 0, 0))\n",
    "imsave('imgs/out.png', img)\n",
    "Image('imgs/out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 26\n",
    "nbrows = 6\n",
    "nbcols = 6\n",
    "border = 1\n",
    "space = 10\n",
    "scores = {}\n",
    "SIZE = 4\n",
    "s = (28+border) * SIZE + border\n",
    "MODEL = 'aa'\n",
    "ims = {}\n",
    "letters = {}\n",
    "classes = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "img_all = np.ones((nbrows * (s+space), nbcols * (s+space)  ))\n",
    "for i in range(nbrows):\n",
    "    for j in range(nbcols):\n",
    "        indices = np.arange(len(datasets[MODEL]))\n",
    "        if i*nbcols+j>=nb_classes:\n",
    "            break\n",
    "        pr_all = preds_per_dataset[MODEL]\n",
    "        p=preds_per_dataset[MODEL][:, i*nbcols+j]        \n",
    "        indices = np.arange(len(datasets[MODEL]))\n",
    "        indices = indices[np.argsort(p[indices])[::-1]]\n",
    "        #indices = indices[pr_all[indices][:, 10:].sum(axis=1)>0.95]\n",
    "        img = datasets[MODEL][indices[0:SIZE*SIZE]]\n",
    "        scores[i*nbcols+j] = p[indices].copy()\n",
    "        #print(p[indices][0:16])\n",
    "        #letters[classes[i*nbcols+j]] = img[np.random.randint(0, 4)]\n",
    "        #letters[classes[i*nbcols+j]] = img[manual[classes[i*nbcols+j]]]\n",
    "        letters[classes[i*nbcols+j]] = img[0]\n",
    "        img = disp_grid(img[0:SIZE*SIZE], border=border, bordercolor=(0.3, 0, 0), shape=(SIZE,SIZE))\n",
    "        img_all[i*(s+space):i*(s+space) + s, j*(s+space):j*(s+space) + s] = img[:,:,0]\n",
    "#img_all = 1 - img_all\n",
    "imsave('imgs/all.png', img_all)\n",
    "Image('imgs/all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pan = [\n",
    "    \"Pack my box with five dozen liquor jugs\".lower(),\n",
    "    \"Jackdaws love my big sphinx of quartz\".lower(),\n",
    "    \"The five boxing wizards jump quickly.\".lower(),\n",
    "    \"How vexingly quick daft zebras jump\".lower(),\n",
    "    \"Bright vixens jump dozy fowl quack\".lower(),\n",
    "    \"Sphinx of black quartz, judge my vow\".lower(),\n",
    "]\n",
    "for s in pan:\n",
    "    pangram = np.zeros((28 , 28 * len(s)))\n",
    "    i = 0\n",
    "    for l in s:\n",
    "        if l not in letters:\n",
    "            i += 28\n",
    "            continue\n",
    "        pangram[0:28, i:i+28] = letters[l]\n",
    "\n",
    "        i += 24\n",
    "    pangram = 1 - pangram\n",
    "    imsave('out.png', pangram)\n",
    "    display(Image('out.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking stats of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = load_db()\n",
    "jobs = db.jobs_with(state=SUCCESS, where='jobset83')\n",
    "S = [j['summary'] for j in jobs]\n",
    "jobs_gen = to_generation(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 'stats.out_of_the_box_classification.fonts.objectness'\n",
    "jobs_gen = to_generation(jobs)\n",
    "\n",
    "def sort_by(jobs, k):\n",
    "    indices = np.arange(len(jobs_gen))\n",
    "    def key(i):\n",
    "        val = db.get_value(jobs_gen[i], k, if_not_found=None)\n",
    "        if val is None or np.isnan(val):\n",
    "            val = -np.inf\n",
    "        return val\n",
    "    indices = sorted(indices, key=key)\n",
    "    vals = [key(ind) for ind in indices]\n",
    "    return indices[::-1], vals[::-1]\n",
    "\n",
    "indices, vals = sort_by(jobs, k)\n",
    "\n",
    "interesting = [\n",
    "    jobs_gen[ind]['summary']\n",
    "    for ind in indices[0:10]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = 20\n",
    "k1 = 'stats.out_of_the_box_classification.fonts.objectness'\n",
    "indices, vals = sort_by(jobs, k1)\n",
    "s1 = [jobs[ind]['summary'] for ind in indices[0:nb]]\n",
    "k2 = 'stats.out_of_the_box_classification.letterness.diversity_count_letters_99'\n",
    "indices, vals = sort_by(jobs, k2)\n",
    "s2 = [jobs[ind]['summary'] for ind in indices[0:nb]]\n",
    "k3 = 'stats.out_of_the_box_classification.letterness.diversity_max_letters'\n",
    "indices, vals = sort_by(jobs, k3)\n",
    "s3 = [jobs[ind]['summary'] for ind in indices[0:nb]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(set(s1).intersection(set(s2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#m = list((set(s1).intersection(set(s2)).intersection(set(s3))  ))\n",
    "m = list(set(s1).intersection(s2))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "I = 8\n",
    "db.get_job_by_summary(m[I])['content']['model_params'], m[I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.common import find_generation_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Intersect on s1 and s2, top 20, AA\n",
    "summaries = [\n",
    "    '9c5cc9c315ad13f6e1151200f885d54a',\n",
    "    'a3a97a790acf41b122a94af93834a301',\n",
    "    '1b5f929796b52352a009ab37f602bfbf', # used\n",
    "    '0396380c8787034efd079b32a51d9dd6', #used\n",
    "    '6c761ed85005ba530a636fcc2a751c1d',#used\n",
    "]\n",
    "# \n",
    "gen_summ = [\n",
    "    find_generation_job(s)['summary']\n",
    "    for s in summaries\n",
    "]\n",
    "for s in gen_summ:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in summaries[2:]:\n",
    "    print(db.get_job_by_summary(s)['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "field = 'stats.out_of_the_box_classification.letterness.count_fonts'\n",
    "indices = np.arange(len(jobs))\n",
    "for i in range(len(jobs_gen)):\n",
    "    j = jobs_gen[i]\n",
    "    v = db.get_value(j, field, if_not_found=None)\n",
    "    #if not v:print('Misssing generation jobs from training job : {}, skip it.'.format(jobs[i]['summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.arange(len(jobs))\n",
    "objectness = map(lambda j:db.get_value(j, field, if_not_found=np.nan), jobs_gen)\n",
    "objectness = np.array(objectness)\n",
    "indices = filter(lambda ind:not np.isnan(objectness[ind]), indices)\n",
    "indices = sorted(indices, key=lambda i:objectness[i])\n",
    "indices = indices[::-1]\n",
    "images = ['../exported_data/figs/generated/jobset{:05d}/{}.png'.format(int(jobs[i]['where'][6:]), jobs_gen[i]['summary']) \n",
    "          for i in indices]\n",
    "for i in range(len(images)):\n",
    "    #print(jobs_gen[indices[i]]['summary'])\n",
    "    shutil.copy(images[i], 'export/{:05d}.png'.format(i))\n",
    "    #if i<20:\n",
    "    #    display(Image(images[i], width=600, height=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## images = joblib.load('../jobs/results/a7080dba22d7e429bf70bf4c1899dc32/images.npz')\n",
    "images = images[:, -1]\n",
    "print(images.sum())\n",
    "print(images.shape)\n",
    "images = images #/ float(images.max())\n",
    "print(images.min(), images.max())\n",
    "print(images.sum())\n",
    "pr = model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fonts = np.load('/home/mcherti/work/data/fonts/fonts.npz')\n",
    "fonts_X = fonts['X']\n",
    "fonts_X = fonts_X / 255.\n",
    "fx = fonts_X[0:1000]\n",
    "fx = resize_set(fx, 28, 28)\n",
    "fx = 1 - fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = model.predict(fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(x):\n",
    "    return -np.dot(x, np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_proba_letters = pr[:, 10:]\n",
    "theta = 0.9\n",
    "selected_letters = (pred_proba_letters.max(axis=1) > theta)\n",
    "ent = entropy(probas_from_occurences(pred_proba_letters[selected_letters].argmax(axis=1))) / np.log(26)\n",
    "print(selected_letters.mean() + ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_objectness(v):\n",
    "    v = np.array(v)\n",
    "    marginal = v.mean(axis=0)\n",
    "    score = v * np.log(v / marginal)\n",
    "    score = score.sum(axis=1).mean()\n",
    "    score = np.exp(score)\n",
    "    score = float(score)\n",
    "    return score\n",
    "compute_objectness(pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## objectness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objectness = compute_sample_objectness_renyi(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = np.argsort(objectness)[::-1]\n",
    "X_sorted = X[ind]\n",
    "preds_sorted = preds[ind]\n",
    "objectness_sorted = objectness[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = np.arange(len(X))\n",
    "np.random.shuffle(sample)\n",
    "sample = sample[0:100]\n",
    "objectness_sampled = objectness[sample]\n",
    "X_sampled = X[sample]\n",
    "preds_sampled = preds[sample]\n",
    "X_sampled = X_sampled[np.argsort(objectness_sampled)[::-1]]\n",
    "preds_sampled = preds_sampled[np.argsort(objectness_sampled)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = disp_grid_with_pred(X_sorted[0::1000], preds_sorted[0::1000], h=200)\n",
    "imsave('imgs/out.png', im)\n",
    "Image('imgs/out.png', width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interesting= [\n",
    "\"014c75c6714d739aee7259a321971e9c\",\n",
    "\"01634d66ca2f265505c8e3c19dabfc08\",\n",
    "\"01c78a7a5974a03c7bf9386bceea0ccc\",\n",
    "\"0589a90fb79fab1eb30a896ab7e82157\",\n",
    "\"075bfc928d21ecc4dbf2726d08080466\",\n",
    "\"093d320192b53610a447eb55ae42541b\",\n",
    "\"0a0794aad864797fe90f00f02fffcacd\",\n",
    "\"0a3b974348b7a6b4d2540f37898f52b9\",\n",
    "\"0a4827cdf66a65e1355a28db0338016c\",\n",
    "\"0acf9872f8a68ffd86388175e337794b\",\n",
    "\"0ad7ef561f6f48312cd552a1a2742a02\",\n",
    "\"0afd2e2fe618625084d7f23f331811ee\",\n",
    "\"0b6b873ba7dffe6f9824b9ced6184266\",\n",
    "\"1207cc0a53862d926f35e22b822555d9\",\n",
    "\"14ad5a8bb42e245a69bdad3d0fef4c4a\",\n",
    "\"1676800b0388dc29a77b64ef0078c916\",\n",
    "\"1b7d9d5c502aa2101c190fb91a5bfdea\",\n",
    "\"1bcbb8839774e00c6e84edd345432108\",\n",
    "\"1d3f210dc793a588638f0251cb6ea0c4\",\n",
    "\"1dc52531190cf9129676e1903d376feb\",\n",
    "\"1f64aa37b468f3246f240b261117694a\",\n",
    "\"2188d0535c3fb0ed9c8a82d922629d88\",\n",
    "\"21ec0a06557ca67574322579a2edd17e\",\n",
    "\"27c31ab04817b8aabd726e4b735ed2e8\",\n",
    "\"2c364593260fd6afceb7f270c72b1720\",\n",
    "\"3246e5a1dd2b4ef900ea9dbca91450a9\",\n",
    "\"343ed87ba5a1bb6df197f485a6d4fd4c\",\n",
    "\"36933fb2fc340a7277a45469f8891b59\",\n",
    "\"39c48512bcfba7adbf8981f0f528aed2\",\n",
    "\"3a1fc241e455e5c171abb0d553cfd7a6\",\n",
    "\"3b7538f5b5561e7628da0efc1d711be6\",\n",
    "\"3f970e54af5bfce6a26ddf76e0ff2648\",\n",
    "\"416b0c2bc209aae34533a19dbe21e123\",\n",
    "\"4527d2a503622dfcfadde0707c45d09d\",\n",
    "\"45d586ec0faf4adae82f920733a18d5c\",\n",
    "\"48fd385467bf47bc5eefa485581331fe\",\n",
    "\"4cfa603a7ea384786196634bff9256e3\",\n",
    "\"4f9870c8ae68854360786e743453f929\",\n",
    "\"517302ec5da070804fd729e9bd44fdc8\",\n",
    "\"53e03350ee1ab88baebce3666ebbb0c6\",\n",
    "\"542cb46231f30d1e2aac5682f1e38d53\",\n",
    "\"55e1972878256226fb2369c19967ea78\",\n",
    "\"561ce9963bf2d6a14779f2764f59b341\",\n",
    "\"5c640320afe2a45bca400f4ae5df2973\",\n",
    "\"611cfe20db4f8290196166e5ad7335a6\",\n",
    "\"690f0fc689eecd14b7198fc34b605870\",\n",
    "\"6aaf83165a07d97f79755fe0579a27cc\",\n",
    "\"7327ad57b2a2e1ae7193c339e4ec0de8\",\n",
    "\"73da00fd56f4bba3a9cf4502d045ef70\",\n",
    "\"74481f32be588d6c783b4ef6052d8bc7\",\n",
    "\"77aaf83e42fa16c30d09f51aff159d6e\",\n",
    "\"77f66fa1d3ac15604d78a907f0a9a20a\",\n",
    "\"7abf2cd29ba129a5ee2bc3a7b4274411\",\n",
    "\"7b7311a13a7d2df8b64c9d5ea5f253e1\",\n",
    "\"7dacf0429cb8624805444b6efb413023\",\n",
    "\"7e528009eacf89cd993333ba568087d3\",\n",
    "\"80b0469a717600c5c4192bad51a53fc2\",\n",
    "\"8c3d35136bce99a3b18f97c06398f24a\",\n",
    "\"8fd2c3f14f7454ff3d41db32c6326eba\",\n",
    "\"907e85a66293d7c3675211f5606f09c4\",\n",
    "\"91d32b40bff2db047c5dc159efcfc039\",\n",
    "\"9587e2c657e4d938ce0a9f9b65501327\",\n",
    "\"9838c215f3adff337d76ed2833d4422e\",\n",
    "\"9ae47ca6036fb6f0ff1a5bba3983ffed\",\n",
    "\"9b2b3b421cb78d8a79027ae89bb306f3\",\n",
    "\"9bd7b7a63fa26d8402c5a203c70410a7\",\n",
    "\"9c3715767177310f52ae08016b240530\",\n",
    "\"9eb70ae4ce570f75a9ee59f39e0951e5\",\n",
    "\"a1536081d9fd8608da3325ca4ee9905e\",\n",
    "\"a3b04bf19e475f7125140e54c3ef8f74\",\n",
    "\"ac10e381c17ac61b6ed822d9d216ae2c\",\n",
    "\"cd72451891a553a4043ea8e5b657047e\",\n",
    "\"cee374a04a97803f533c8c0f8d96e18e\",\n",
    "\"d0ac4556f27fa33995578444a4a48c9a\",\n",
    "\"d72f7805cd378983bc591a751f5a59ee\",\n",
    "\"dd59ef42eb7f7ba455349e3d055f9009\",\n",
    "\"e1e83ef0c191df696eeac035b85f01da\",\n",
    "\"e441573f5cebdaffbfba4ca1d31dda51\",\n",
    "\"e527e0b59433177b40e1a6d3f63dbd45\",\n",
    "\"e7d16968a99c3bb7434868747fd82be8\",\n",
    "\"ef7f645925ab8eb02075832ca3133033\",\n",
    "\"f1389e44c90189e64c46e7835bc12021\",\n",
    "\"f3aff216ae60e8872b045b061cd7ec91\",\n",
    "\"f4a6ef879821e31b2e1f8ab30f1e0379\",\n",
    "\"fa64d29a142b33ffec1e11d1a31aff99\",\n",
    "\"fda1b25645be6f69bbed7aac3add2cb8\",\n",
    "\"ff28f39727c9266eacd10e86e85170be\",\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for s in interesting:\n",
    "    filename = '../jobs/results/{}/images.npz'.format(s)\n",
    "    images.append(preprocess_gen_data(joblib.load(filename))[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.concatenate(images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = X.copy()\n",
    "S[:, 0, 0, 0:]=0.5\n",
    "S[:, 0, -1, 0:]=0.5\n",
    "S[:, 0, 0:, 0]=0.5\n",
    "S[:, 0, 0:, -1]=0.5\n",
    "R = X.copy()\n",
    "R = encode(R)\n",
    "R = R.reshape((X.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model('../jobs/results/1b5f929796b52352a009ab37f602bfbf/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model, data, layers = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import lasagne.layers as L\n",
    "import theano.tensor as T\n",
    "xt = T.tensor4()\n",
    "encode = theano.function([xt], L.get_output(layers['hid5'], xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#R = encode(X)\n",
    "R = X.reshape((X.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43500, 50)\n"
     ]
    }
   ],
   "source": [
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clus = KMeans(n_clusters=1000)\n",
    "clus.fit(R[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_clus = (clus.predict(R)==240)\n",
    "img = disp_grid(X[R_clus][0:16], border=1, bordercolor=(0.3, 1, 1))\n",
    "img = 1 - img\n",
    "imsave('out_scatter.png', img)\n",
    "Image('out_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d10e143582ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#R= TSNE(perplexity=15).fit_transform(R)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_scatter.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out_scatter.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mcherti/work/code/feature_generation/tools/viz/image_scatter.py\u001b[0m in \u001b[0;36mimage_scatter\u001b[0;34m(f2d, images, img_res, res, cval)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mImage\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgray_to_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmin_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_res\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from tools.viz.image_scatter import image_scatter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "R = PCA(n_components=50).fit_transform(R)\n",
    "#R= TSNE(perplexity=15).fit_transform(R)\n",
    "#img = image_scatter(R, 0, 40, res=4000)\n",
    "\n",
    "\n",
    "imsave('out_scatter.png', img)\n",
    "Image('out_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:databoard-env]",
   "language": "python",
   "name": "conda-env-databoard-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
